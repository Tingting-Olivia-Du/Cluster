{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOXMC2q9DKG8K8wPqvH98ZI"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lUuyqc8xO42W","executionInfo":{"status":"ok","timestamp":1753021905452,"user_tz":-480,"elapsed":24596,"user":{"displayName":"Tingting Du","userId":"01262363838823204487"}},"outputId":"c2cd051c-5248-4b19-b0de-cda8f27cee04"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","\n","# ✅ 挂载 Google Drive\n","drive.mount('/content/drive')\n"]},{"cell_type":"code","source":["# -*- coding: utf-8 -*-\n","\"\"\"\n","feature_detector.py\n","\n","端到端脚本：\n","1) 从 JSON 文件加载正负采样的 token-level 熵序列 和 错误/修正位置信息；\n","2) 提取时域 & 频域统计特征；\n","3) 拼接成分类特征向量并打标签（负样本=1，正样本=0）；\n","4) 训练 LogisticRegression 二分类器并评估性能。\n","\"\"\"\n","\n","import os\n","import json\n","import numpy as np\n","import pandas as pd\n","from scipy.fft import fft, fftfreq\n","from scipy.signal import find_peaks\n","from scipy.stats import skew, kurtosis\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.metrics import classification_report, roc_auc_score\n","\n","# ---------- 配置项，请修改为你本地的实际路径 ----------\n","BASE_PATH      = \"/content/drive/MyDrive/Cluster-proj\"\n","start_index    = 700\n","end_index      = 731\n","range_tag      = f\"{start_index}-{end_index}\"\n","LOGITS_PATH    = f\"{BASE_PATH}/output/llm_steps/whole_logits/deepseek7b-gsm-{range_tag}.json\"\n","INDEX_PATH     = f\"{BASE_PATH}/output/error_fix_index/deepseek-7b-{range_tag}_error_fix_index.json\"\n","\n","# ---------- 核心工具函数 ----------\n","\n"],"metadata":{"id":"FPeZb7_6O-9u","executionInfo":{"status":"ok","timestamp":1753022359814,"user_tz":-480,"elapsed":1686,"user":{"displayName":"Tingting Du","userId":"01262363838823204487"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["# 1. 加载 JSON\n","with open(LOGITS_PATH, 'r') as f:\n","    logits_data = json.load(f)\n","with open(INDEX_PATH, 'r') as f:\n","    index_data  = json.load(f)"],"metadata":{"id":"YLGpujfITnkB","executionInfo":{"status":"ok","timestamp":1753022897086,"user_tz":-480,"elapsed":374,"user":{"displayName":"Tingting Du","userId":"01262363838823204487"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["# -*- coding: utf-8 -*-\n","\"\"\"\n","feature_detector.py\n","\n","端到端脚本：\n","1) 从 JSON 文件加载正负采样的 token-level 熵序列 和 错误/修正位置信息；\n","2) 只使用 sampling* 字段及其 correct_sampling_id 构建正负样本对；\n","3) 提取时域 & 频域统计特征；\n","4) 拼接成分类特征向量并打标签（负样本=1，正样本=0）；\n","5) 训练 LogisticRegression 二分类器并评估性能。\n","\"\"\"\n","\n","import os\n","import json\n","import numpy as np\n","import pandas as pd\n","from scipy.fft import fft, fftfreq\n","from scipy.signal import find_peaks\n","from scipy.stats import skew, kurtosis\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.metrics import classification_report, roc_auc_score\n","\n","# ---------- 配置（修改为本地路径） ----------\n","BASE_PATH   = \"/content/drive/MyDrive/Cluster-proj\"\n","start_index = 700\n","end_index   = 731\n","range_tag   = f\"{start_index}-{end_index}\"\n","LOGITS_PATH = f\"{BASE_PATH}/output/llm_steps/whole_logits/deepseek7b-gsm-{range_tag}.json\"\n","INDEX_PATH  = f\"{BASE_PATH}/output/error_fix_index/deepseek-7b-{range_tag}_error_fix_index.json\"\n","\n","# ---------- 特征提取函数 ----------\n","def extract_time_features(entropy):\n","    feats = {\n","        'mean': np.mean(entropy),\n","        'var': np.var(entropy),\n","        'skew': skew(entropy),\n","        'kurtosis': kurtosis(entropy),\n","        'max': np.max(entropy),\n","        'min': np.min(entropy)\n","    }\n","    peaks, props = find_peaks(entropy, height=None)\n","    feats['peak_count']    = len(peaks)\n","    feats['peak_prom_avg'] = float(np.mean(props['prominences'])) if 'prominences' in props else 0.0\n","    feats['autocorr1']     = float(np.corrcoef(entropy[:-1], entropy[1:])[0,1]) if len(entropy)>1 else 0.0\n","    return feats\n","\n","def extract_freq_features(entropy):\n","    N  = len(entropy)\n","    yf = fft(entropy)\n","    xf = fftfreq(N, d=1)[:N//2]\n","    amp = np.abs(yf)[:N//2]\n","    power = amp**2\n","    total = np.sum(power) + 1e-8\n","\n","    feats = {}\n","    feats['spec_centroid']      = float(np.sum(xf * amp) / (np.sum(amp)+1e-8))\n","    feats['band_mid_high_ratio']= float(np.sum(power[xf>0.1]) / total)\n","    geo_mean = np.exp(np.mean(np.log(power+1e-8)))\n","    feats['spec_flatness']      = float(geo_mean / (np.mean(power)+1e-8))\n","    csum = np.cumsum(power)\n","    idx  = np.where(csum >= 0.85*total)[0][0]\n","    feats['spec_rolloff']       = float(xf[idx])\n","    p_norm = power/total\n","    feats['spec_entropy']       = float(-np.sum(p_norm * np.log2(p_norm+1e-8)))\n","    return feats\n","\n","# ---------- 主流程 ----------\n","def main():\n","\n","\n","    # 2. 构建 sampling 对\n","    paired = []\n","    for qid, meta_dict in index_data.items():\n","        if qid not in logits_data:\n","            continue\n","        for neg_sid, meta in meta_dict.items():\n","            # 只处理 sampling 开头的负样本\n","            if not neg_sid.startswith(\"sampling\"):\n","                continue\n","            pos_sid = meta.get(\"correct_sampling_id\")\n","            # 只有当正样本 ID 在 logits_data 中存在时才配对\n","            if pos_sid in logits_data[qid]:\n","                paired.append((qid, neg_sid, pos_sid))\n","            else:\n","                print(f\"⚠️ 跳过 {qid} | {neg_sid} vs {pos_sid} — 不存在正确采样\")\n","\n","    # 3. 特征提取\n","    records = []\n","    for qid, neg_sid, pos_sid in paired:\n","        try:\n","            neg_probs = logits_data[qid][neg_sid][\"token_probs\"]\n","            pos_probs = logits_data[qid][pos_sid][\"token_probs\"]\n","            neg_seq = [tok[\"topk_info\"][\"entropy\"] for tok in neg_probs]\n","            pos_seq = [tok[\"topk_info\"][\"entropy\"] for tok in pos_probs]\n","        except Exception as e:\n","            print(f\"跳过 {qid} | {neg_sid} vs {pos_sid} — {e}\")\n","            continue\n","\n","        if len(neg_seq)<4 or len(pos_seq)<4:\n","            continue\n","\n","        neg_feats = {f\"neg_{k}\":v for k,v in {**extract_time_features(neg_seq),  **extract_freq_features(neg_seq)}.items()}\n","        pos_feats = {f\"pos_{k}\":v for k,v in {**extract_time_features(pos_seq),  **extract_freq_features(pos_seq)}.items()}\n","\n","        # 负样本=1，正样本=0\n","        records.append({**neg_feats, **pos_feats, \"label\":1})\n","        records.append({**pos_feats, **neg_feats, \"label\":0})\n","\n","    df = pd.DataFrame(records)\n","    X  = df.drop(columns=\"label\")\n","    y  = df[\"label\"]\n","\n","    # 4. 划分训练/测试\n","    X_tr, X_te, y_tr, y_te = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n","\n","    # 5. 标准化\n","    scaler = StandardScaler().fit(X_tr)\n","    X_tr_s = scaler.transform(X_tr)\n","    X_te_s = scaler.transform(X_te)\n","\n","    # 6. 训练分类器\n","    clf = LogisticRegression(max_iter=1000, class_weight='balanced')\n","    clf.fit(X_tr_s, y_tr)\n","\n","    # 7. 评估\n","    y_pred = clf.predict(X_te_s)\n","    y_prob = clf.predict_proba(X_te_s)[:,1]\n","\n","    print(\"=== Classification Report ===\")\n","    print(classification_report(y_te, y_pred, digits=4))\n","    print(\"=== ROC AUC Score ===\")\n","    print(f\"{roc_auc_score(y_te, y_prob):.4f}\")\n","\n","if __name__ == \"__main__\":\n","    main()\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6ROouYpuO-_v","executionInfo":{"status":"ok","timestamp":1753022909248,"user_tz":-480,"elapsed":64,"user":{"displayName":"Tingting Du","userId":"01262363838823204487"}},"outputId":"4c8fea24-7a29-4868-b12b-3e0bd16bee8a"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["=== Classification Report ===\n","              precision    recall  f1-score   support\n","\n","           0     0.0000    0.0000    0.0000         6\n","           1     0.2500    0.4000    0.3077         5\n","\n","    accuracy                         0.1818        11\n","   macro avg     0.1250    0.2000    0.1538        11\n","weighted avg     0.1136    0.1818    0.1399        11\n","\n","=== ROC AUC Score ===\n","0.1333\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"t8Vu90JvO_B1"},"execution_count":null,"outputs":[]}]}
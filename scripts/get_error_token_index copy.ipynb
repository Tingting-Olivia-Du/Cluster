{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 192933,
     "status": "ok",
     "timestamp": 1752394079714,
     "user": {
      "displayName": "Tingting Du",
      "userId": "01262363838823204487"
     },
     "user_tz": -480
    },
    "id": "olcts10oX0nL",
    "outputId": "62b860f6-cd75-4ba6-bc60-56edc268efb1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔄 Converting ../logits/deepseek-math-7b-math-0-15-algebra-level_3.json to JSONL format...\n",
      "📊 Input file size: 1.05 GB\n",
      "📊 Total items to convert: 10\n",
      "✅ Conversion complete! Saved to ../logits/deepseek-math-7b-math-0-15-algebra-level_3.jsonl\n",
      "\n",
      "🚀 Starting JSONL processing...\n",
      "🔍 Processing q_0...\n",
      "⚠️ No valid result for q_0\n",
      "🔍 Processing q_1...\n",
      "  🔍 Analyzing sampling2...\n",
      "  ✅ Successfully analyzed sampling2\n",
      "✅ Successfully processed q_1\n",
      "🔍 Processing q_2...\n",
      "  🔍 Analyzing sampling0...\n",
      "  ✅ Successfully analyzed sampling0\n",
      "✅ Successfully processed q_2\n",
      "🔍 Processing q_3...\n",
      "⚠️ No valid result for q_3\n",
      "🔍 Processing q_4...\n",
      "⚠️ No valid result for q_4\n",
      "💾 Saved 2 results to ../error_fix_index/deepseek-math-7b-math-0-15-algebra-level_3_index.json\n",
      "📊 Progress: 2 processed, 0 errors, 0.23 items/sec, 8.7s elapsed\n",
      "🔍 Processing q_5...\n",
      "  🔍 Analyzing sampling0...\n",
      "  ✅ Successfully analyzed sampling0\n",
      "✅ Successfully processed q_5\n",
      "🔍 Processing q_6...\n",
      "⚠️ No valid result for q_6\n",
      "🔍 Processing q_7...\n",
      "⚠️ No valid result for q_7\n",
      "🔍 Processing q_8...\n",
      "⚠️ No valid result for q_8\n",
      "🔍 Processing q_9...\n",
      "⚠️ No valid result for q_9\n",
      "💾 Saved 3 results to ../error_fix_index/deepseek-math-7b-math-0-15-algebra-level_3_index.json\n",
      "📊 Progress: 3 processed, 0 errors, 0.16 items/sec, 19.2s elapsed\n",
      "💾 Saved 3 results to ../error_fix_index/deepseek-math-7b-math-0-15-algebra-level_3_index.json\n",
      "\n",
      "🎉 Processing complete!\n",
      "📊 Total processed: 3\n",
      "⚠️ Total errors: 0\n",
      "⏱️ Total time: 19.2s\n",
      "🚀 Average speed: 0.16 items/sec\n",
      "\n",
      "✅ All processing complete! Results saved to ../error_fix_index/deepseek-math-7b-math-0-15-algebra-level_3_index.json\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Complete JSONL processor with all required functions\n",
    "\"\"\"\n",
    "\n",
    "import json\n",
    "import os\n",
    "import gc\n",
    "import requests\n",
    "import re\n",
    "import time\n",
    "from pathlib import Path\n",
    "from typing import Iterator, Dict, Any\n",
    "\n",
    "# # ✅ API配置\n",
    "API_KEY = \"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\"\n",
    "MODEL = \"gpt-4.1\"\n",
    "\n",
    "# ✅ 构建错误分析提示词\n",
    "def build_error_prompt(question, true_whole_answer, sample_whole_answer):\n",
    "    \"\"\"构建用于错误分析的提示词\"\"\"\n",
    "    return f\"\"\"\n",
    "Here is a math question, its correct answer, and a sample answer that may contain mistakes.\n",
    "\n",
    "【question】:\n",
    "{question}\n",
    "\n",
    "【Correct Answer】:\n",
    "{true_whole_answer}\n",
    "\n",
    "【Incorrect Answer】:\n",
    "{sample_whole_answer}\n",
    "\n",
    "Please help me:\n",
    "1. Identify the earliest mistake in the incorrect answer and provide the complete sentence from that point.\n",
    "2. Briefly explain why it is incorrect.\n",
    "3. Find the fix sentence in correct answer that and fix the error.\n",
    "4. Briefly explain why it can fix the error.\n",
    "\n",
    "Please output in the following JSON format:\n",
    "{{\n",
    "  \"first_error_sentence\": \"<sentence>\",\n",
    "  \"error_reason\": \"<brief explanation>\",\n",
    "  \"fix_sentence\": \"<sentence>\",\n",
    "  \"fix_reason\": \"<brief explanation>\"\n",
    "}}\n",
    "\"\"\"\n",
    "\n",
    "# ✅ 调用GPT API\n",
    "def call_custom_gpt_api(prompt):\n",
    "    \"\"\"调用OpenAI API\"\"\"\n",
    "    headers = {\n",
    "        \"Authorization\": f\"Bearer {API_KEY}\",\n",
    "        \"Content-Type\": \"application/json\"\n",
    "    }\n",
    "    payload = {\n",
    "        \"model\": MODEL,\n",
    "        \"messages\": [\n",
    "            {\"role\": \"system\", \"content\": \"You are a meticulous and precise comparer.\"},\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ]\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        response = requests.post(\n",
    "            \"https://api.openai.com/v1/chat/completions\",\n",
    "            headers=headers,\n",
    "            json=payload,\n",
    "            timeout=30  # 添加超时\n",
    "        )\n",
    "\n",
    "        if response.status_code != 200:\n",
    "            raise Exception(f\"API request failed: {response.status_code}, {response.text}\")\n",
    "\n",
    "        return response.json()[\"choices\"][0][\"message\"][\"content\"]\n",
    "\n",
    "    except requests.exceptions.Timeout:\n",
    "        raise Exception(\"API request timeout\")\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        raise Exception(f\"API request error: {str(e)}\")\n",
    "\n",
    "# ✅ 查找句子在token序列中的位置\n",
    "def find_sentence_span_indices_robust(fragment, token_probs):\n",
    "    \"\"\"\n",
    "    返回 fragment 在 token_probs 中匹配到的 token 范围: (begin_index, end_index)\n",
    "    使用去除空白字符的方式匹配\n",
    "    \"\"\"\n",
    "    if not fragment or not token_probs:\n",
    "        return -1, -1\n",
    "\n",
    "    fragment_clean = re.sub(r\"\\s+\", \"\", fragment)\n",
    "    tokens = [entry[\"token\"] for entry in token_probs]\n",
    "    decoded_text = \"\".join(tokens)\n",
    "    decoded_text_clean = re.sub(r\"\\s+\", \"\", decoded_text)\n",
    "\n",
    "    char_start_idx = decoded_text_clean.find(fragment_clean)\n",
    "    if char_start_idx == -1:\n",
    "        return -1, -1\n",
    "\n",
    "    cumulative_len = 0\n",
    "    begin_index = -1\n",
    "\n",
    "    for idx, entry in enumerate(token_probs):\n",
    "        token_clean = re.sub(r\"\\s+\", \"\", entry[\"token\"])\n",
    "        prev_len = cumulative_len\n",
    "        cumulative_len += len(token_clean)\n",
    "\n",
    "        if begin_index == -1 and cumulative_len > char_start_idx:\n",
    "            begin_index = idx\n",
    "        if cumulative_len >= char_start_idx + len(fragment_clean):\n",
    "            end_index = idx\n",
    "            return begin_index, end_index\n",
    "\n",
    "    return begin_index, len(token_probs) - 1  # fallback\n",
    "\n",
    "class JSONLProcessor:\n",
    "    \"\"\"\n",
    "    高效的JSONL处理器，支持内存管理和进度跟踪\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, api_key: str, model: str = \"gpt-4.1\"):\n",
    "        self.api_key = api_key\n",
    "        self.model = model\n",
    "        self.processed_count = 0\n",
    "        self.error_count = 0\n",
    "        self.start_time = None\n",
    "\n",
    "    def convert_json_to_jsonl(self, input_path: str, output_path: str,\n",
    "                             chunk_size: int = 1000):\n",
    "        \"\"\"\n",
    "        将大JSON文件转换为JSONL，支持分块处理\n",
    "        \"\"\"\n",
    "        print(f\"🔄 Converting {input_path} to JSONL format...\")\n",
    "\n",
    "        # 创建输出目录\n",
    "        os.makedirs(os.path.dirname(output_path), exist_ok=True)\n",
    "\n",
    "        # 检查文件大小\n",
    "        file_size = os.path.getsize(input_path)\n",
    "        print(f\"📊 Input file size: {file_size / (1024**3):.2f} GB\")\n",
    "\n",
    "        with open(input_path, 'r', encoding='utf-8') as infile:\n",
    "            data = json.load(infile)\n",
    "\n",
    "        total_items = len(data)\n",
    "        print(f\"📊 Total items to convert: {total_items}\")\n",
    "\n",
    "        with open(output_path, 'w', encoding='utf-8') as outfile:\n",
    "            for i, (qid, sample) in enumerate(data.items()):\n",
    "                line_data = {\n",
    "                    \"qid\": qid,\n",
    "                    \"data\": sample\n",
    "                }\n",
    "                outfile.write(json.dumps(line_data, ensure_ascii=False) + '\\n')\n",
    "\n",
    "                if (i + 1) % chunk_size == 0:\n",
    "                    print(f\"📈 Converted {i + 1}/{total_items} items...\")\n",
    "                    # 强制刷新到磁盘\n",
    "                    outfile.flush()\n",
    "\n",
    "        print(f\"✅ Conversion complete! Saved to {output_path}\")\n",
    "\n",
    "        # 清理内存\n",
    "        del data\n",
    "        gc.collect()\n",
    "\n",
    "    def process_jsonl_file(self, jsonl_path: str, output_path: str,\n",
    "                          batch_size: int = 10, save_interval: int = 20):\n",
    "        \"\"\"\n",
    "        流式处理JSONL文件，支持批处理和定期保存\n",
    "        \"\"\"\n",
    "        self.start_time = time.time()\n",
    "        results = {}\n",
    "\n",
    "        # 如果输出文件已存在，加载已处理的结果\n",
    "        if os.path.exists(output_path):\n",
    "            print(\"📂 Loading existing results...\")\n",
    "            try:\n",
    "                with open(output_path, 'r', encoding='utf-8') as f:\n",
    "                    results = json.load(f)\n",
    "                    self.processed_count = len(results)\n",
    "                    print(f\"📊 Loaded {self.processed_count} existing results\")\n",
    "            except (json.JSONDecodeError, FileNotFoundError):\n",
    "                print(\"⚠️ Could not load existing results, starting fresh\")\n",
    "                results = {}\n",
    "\n",
    "        # 创建输出目录\n",
    "        os.makedirs(os.path.dirname(output_path), exist_ok=True)\n",
    "\n",
    "        with open(jsonl_path, 'r', encoding='utf-8') as f:\n",
    "            batch = []\n",
    "            line_count = 0\n",
    "\n",
    "            for line in f:\n",
    "                try:\n",
    "                    line_data = json.loads(line.strip())\n",
    "                    qid = line_data[\"qid\"]\n",
    "\n",
    "                    # 跳过已处理的项目\n",
    "                    if qid in results:\n",
    "                        print(f\"⏭️ Skipping already processed: {qid}\")\n",
    "                        continue\n",
    "\n",
    "                    batch.append((qid, line_data[\"data\"]))\n",
    "                    line_count += 1\n",
    "\n",
    "                    # 处理批次\n",
    "                    if len(batch) >= batch_size:\n",
    "                        self._process_batch(batch, results)\n",
    "                        batch = []\n",
    "\n",
    "                        # 定期保存和清理内存\n",
    "                        if line_count % save_interval == 0:\n",
    "                            self._save_results(results, output_path)\n",
    "                            gc.collect()\n",
    "                            self._print_progress()\n",
    "\n",
    "                except json.JSONDecodeError as e:\n",
    "                    print(f\"⚠️ JSON decode error in line: {e}\")\n",
    "                    continue\n",
    "                except Exception as e:\n",
    "                    print(f\"⚠️ Unexpected error processing line: {e}\")\n",
    "                    continue\n",
    "\n",
    "            # 处理剩余的项目\n",
    "            if batch:\n",
    "                self._process_batch(batch, results)\n",
    "\n",
    "        # 最终保存\n",
    "        self._save_results(results, output_path)\n",
    "        self._print_final_stats()\n",
    "\n",
    "        return results\n",
    "\n",
    "    def _process_batch(self, batch: list, results: dict):\n",
    "        \"\"\"处理一个批次的数据\"\"\"\n",
    "        for qid, sample in batch:\n",
    "            try:\n",
    "                print(f\"🔍 Processing {qid}...\")\n",
    "                result = self._process_single_sample(qid, sample)\n",
    "                if result:\n",
    "                    results[qid] = result\n",
    "                    self.processed_count += 1\n",
    "                    print(f\"✅ Successfully processed {qid}\")\n",
    "                else:\n",
    "                    print(f\"⚠️ No valid result for {qid}\")\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"⚠️ Error processing {qid}: {str(e)}\")\n",
    "                self.error_count += 1\n",
    "                continue\n",
    "\n",
    "    def _process_single_sample(self, qid: str, sample: dict) -> dict:\n",
    "        \"\"\"处理单个样本\"\"\"\n",
    "        try:\n",
    "            question = sample.get(\"question\", \"\")\n",
    "            true_final_result = sample.get(\"true_final_result\", \"\")\n",
    "\n",
    "            if not question or not true_final_result:\n",
    "                print(f\"⚠️ Missing question or true_final_result for {qid}\")\n",
    "                return None\n",
    "\n",
    "            # 找到正样本\n",
    "            correct_sampling_id = None\n",
    "            correct_sample_answer = None\n",
    "\n",
    "            for sampling_id in [\"sampling0\", \"sampling1\", \"sampling2\"]:\n",
    "                if sampling_id not in sample:\n",
    "                    continue\n",
    "                sampling_data = sample[sampling_id]\n",
    "                if sampling_data.get(\"final_result\") == true_final_result:\n",
    "                    correct_sampling_id = sampling_id\n",
    "                    correct_sample_answer = sampling_data.get(\"whole_answer\", \"\")\n",
    "                    break\n",
    "\n",
    "            if correct_sample_answer is None:\n",
    "                print(f\"⚠️ No correct sampling found for {qid}\")\n",
    "                return None\n",
    "\n",
    "            sample_results = {}\n",
    "\n",
    "            # 处理负样本\n",
    "            for sampling_id in [\"sampling0\", \"sampling1\", \"sampling2\"]:\n",
    "                if sampling_id not in sample:\n",
    "                    continue\n",
    "                sampling = sample[sampling_id]\n",
    "\n",
    "                # 跳过正样本\n",
    "                if sampling.get(\"final_result\") == true_final_result:\n",
    "                    continue\n",
    "\n",
    "                incorrect_sample_answer = sampling.get(\"whole_answer\", \"\")\n",
    "                if not incorrect_sample_answer:\n",
    "                    continue\n",
    "\n",
    "                try:\n",
    "                    print(f\"  🔍 Analyzing {sampling_id}...\")\n",
    "\n",
    "                    # 调用API\n",
    "                    prompt = build_error_prompt(question, correct_sample_answer, incorrect_sample_answer)\n",
    "                    output = call_custom_gpt_api(prompt)\n",
    "\n",
    "                    # 解析结果\n",
    "                    output = output.strip().strip(\"```\")\n",
    "                    if output.startswith(\"json\"):\n",
    "                        output = output[4:].strip()\n",
    "\n",
    "                    output_json = json.loads(output)\n",
    "\n",
    "                    # 查找token索引\n",
    "                    error_sentence = output_json.get(\"first_error_sentence\", \"\")\n",
    "                    fix_sentence = output_json.get(\"fix_sentence\", \"\")\n",
    "\n",
    "                    error_token_probs = sampling.get(\"token_probs\", [])\n",
    "                    correct_token_probs = sample[correct_sampling_id].get(\"token_probs\", [])\n",
    "\n",
    "                    error_begin_idx, error_end_idx = find_sentence_span_indices_robust(\n",
    "                        error_sentence, error_token_probs\n",
    "                    )\n",
    "                    fix_begin_idx, fix_end_idx = find_sentence_span_indices_robust(\n",
    "                        fix_sentence, correct_token_probs\n",
    "                    )\n",
    "\n",
    "                    sample_results[sampling_id] = {\n",
    "                        \"first_error_sentence\": error_sentence,\n",
    "                        \"error_reason\": output_json.get(\"error_reason\", \"\"),\n",
    "                        \"fix_sentence\": fix_sentence,\n",
    "                        \"fix_reason\": output_json.get(\"fix_reason\", \"\"),\n",
    "                        \"correct_sampling_id\": correct_sampling_id,\n",
    "                        \"error_token_begin_index\": error_begin_idx,\n",
    "                        \"error_token_end_index\": error_end_idx,\n",
    "                        \"fix_token_begin_index\": fix_begin_idx,\n",
    "                        \"fix_token_end_index\": fix_end_idx\n",
    "                    }\n",
    "\n",
    "                    print(f\"  ✅ Successfully analyzed {sampling_id}\")\n",
    "\n",
    "                except json.JSONDecodeError as e:\n",
    "                    print(f\"  ⚠️ JSON decode error for {sampling_id}: {e}\")\n",
    "                    continue\n",
    "                except Exception as e:\n",
    "                    print(f\"  ⚠️ Error analyzing {sampling_id}: {e}\")\n",
    "                    continue\n",
    "\n",
    "            return sample_results if sample_results else None\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"⚠️ Error in _process_single_sample for {qid}: {e}\")\n",
    "            return None\n",
    "\n",
    "    def _save_results(self, results: dict, output_path: str):\n",
    "        \"\"\"保存结果到文件\"\"\"\n",
    "        try:\n",
    "            with open(output_path, 'w', encoding='utf-8') as f:\n",
    "                json.dump(results, f, ensure_ascii=False, indent=2)\n",
    "            print(f\"💾 Saved {len(results)} results to {output_path}\")\n",
    "        except Exception as e:\n",
    "            print(f\"⚠️ Error saving results: {e}\")\n",
    "\n",
    "    def _print_progress(self):\n",
    "        \"\"\"打印进度信息\"\"\"\n",
    "        elapsed = time.time() - self.start_time\n",
    "        speed = self.processed_count / elapsed if elapsed > 0 else 0\n",
    "        print(f\"📊 Progress: {self.processed_count} processed, {self.error_count} errors, \"\n",
    "              f\"{speed:.2f} items/sec, {elapsed:.1f}s elapsed\")\n",
    "\n",
    "    def _print_final_stats(self):\n",
    "        \"\"\"打印最终统计信息\"\"\"\n",
    "        elapsed = time.time() - self.start_time\n",
    "        print(f\"\\n🎉 Processing complete!\")\n",
    "        print(f\"📊 Total processed: {self.processed_count}\")\n",
    "        print(f\"⚠️ Total errors: {self.error_count}\")\n",
    "        print(f\"⏱️ Total time: {elapsed:.1f}s\")\n",
    "        if elapsed > 0:\n",
    "            print(f\"🚀 Average speed: {self.processed_count / elapsed:.2f} items/sec\")\n",
    "\n",
    "# ✅ 主函数\n",
    "def main():\n",
    "    # 路径配置\n",
    "    \n",
    "    range_tag = \"0-15\"\n",
    "    level = \"level_3\"\n",
    "    discipline = \"algebra\"\n",
    "    input_json = f\"../logits/deepseek-math-7b-math-{range_tag}-{discipline}-{level}.json\"\n",
    "    output_jsonl = f\"../logits/deepseek-math-7b-math-{range_tag}-{discipline}-{level}.jsonl\"\n",
    "    output_results = f\"../error_fix_index/deepseek-math-7b-math-{range_tag}-{discipline}-{level}_index.json\"\n",
    "\n",
    "    # 创建处理器\n",
    "    processor = JSONLProcessor(API_KEY, MODEL)\n",
    "\n",
    "    # 步骤1: 转换为JSONL（如果还没有转换）\n",
    "    if not os.path.exists(output_jsonl):\n",
    "        processor.convert_json_to_jsonl(input_json, output_jsonl)\n",
    "    else:\n",
    "        print(f\"📂 JSONL file already exists: {output_jsonl}\")\n",
    "\n",
    "    # 步骤2: 处理JSONL文件\n",
    "    print(\"\\n🚀 Starting JSONL processing...\")\n",
    "    results = processor.process_jsonl_file(\n",
    "        jsonl_path=output_jsonl,\n",
    "        output_path=output_results,\n",
    "        batch_size=1,      # 设置为1以便调试\n",
    "        save_interval=5    # 每5个项目保存一次\n",
    "    )\n",
    "\n",
    "    print(f\"\\n✅ All processing complete! Results saved to {output_results}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lYDdlp73XrYe"
   },
   "outputs": [],
   "source": [
    "\n",
    "LOGITS_PATH = \"./logits/deepseek-math-7b-math-{range_tag}.json\"\n",
    "# ✅ Prompt builder\n",
    "def build_error_prompt(question, true_whole_answer, sample_whole_answer):\n",
    "    return f\"\"\"\n",
    "Here is a math problem, its correct answer, and a sample answer that may contain mistakes.\n",
    "\n",
    "【Question】:\n",
    "{question}\n",
    "\n",
    "【Correct Answer】:\n",
    "{true_whole_answer}\n",
    "\n",
    "【Incorrect Answer】:\n",
    "{sample_whole_answer}\n",
    "\n",
    "Please help me:\n",
    "1. Identify the earliest mistake in the incorrect answer and provide the compelete sentence from that point.\n",
    "2. Briefly explain why it is incorrect.\n",
    "3. Find the fix sentence in correct answer that and fix the error.\n",
    "4. Briefly explain why it can fix the error.\n",
    "\n",
    "Please output in the following JSON format:\n",
    "{{\n",
    "  \"first_error_sentence\": \"<sentence>\",\n",
    "  \"error_reason\": \"<brief explanation>\",\n",
    "  \"fix_sentence\": \"<sentence>\",\n",
    "  \"fix_reason\": \"<brief explanation>\"\n",
    "}}\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "# ✅ Call your custom GPT API\n",
    "def call_custom_gpt_api(prompt):\n",
    "    headers = {\n",
    "        \"Authorization\": f\"Bearer {API_KEY}\",\n",
    "        \"Content-Type\": \"application/json\"\n",
    "    }\n",
    "    payload = {\n",
    "        \"model\": MODEL,\n",
    "        \"messages\": [\n",
    "            {\"role\": \"system\", \"content\": \"You are a meticulous and precise comparer.\"},\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ]\n",
    "    }\n",
    "    response = requests.post(\n",
    "        \"https://api.openai.com/v1/chat/completions\",\n",
    "        headers=headers,\n",
    "        json=payload\n",
    "    )\n",
    "    if response.status_code != 200:\n",
    "        raise Exception(f\"API request failed: {response.status_code}, {response.text}\")\n",
    "    return response.json()[\"choices\"][0][\"message\"][\"content\"]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oNoeI-O0WTdr"
   },
   "outputs": [],
   "source": [
    "#version 2\n",
    "\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Advanced JSONL processing with memory management and progress tracking\n",
    "\"\"\"\n",
    "\n",
    "import json\n",
    "import os\n",
    "import gc\n",
    "from pathlib import Path\n",
    "import time\n",
    "from typing import Iterator, Dict, Any\n",
    "\n",
    "class JSONLProcessor:\n",
    "    \"\"\"\n",
    "    高效的JSONL处理器，支持内存管理和进度跟踪\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, api_key: str, model: str = \"gpt-4.1\"):\n",
    "        self.api_key = api_key\n",
    "        self.model = model\n",
    "        self.processed_count = 0\n",
    "        self.error_count = 0\n",
    "        self.start_time = None\n",
    "\n",
    "    def convert_json_to_jsonl(self, input_path: str, output_path: str,\n",
    "                             chunk_size: int = 1000):\n",
    "        \"\"\"\n",
    "        将大JSON文件转换为JSONL，支持分块处理\n",
    "        \"\"\"\n",
    "        print(f\"🔄 Converting {input_path} to JSONL format...\")\n",
    "\n",
    "        # 创建输出目录\n",
    "        os.makedirs(os.path.dirname(output_path), exist_ok=True)\n",
    "\n",
    "        # 检查文件大小\n",
    "        file_size = os.path.getsize(input_path)\n",
    "        print(f\"📊 Input file size: {file_size / (1024**3):.2f} GB\")\n",
    "\n",
    "        with open(input_path, 'r', encoding='utf-8') as infile:\n",
    "            data = json.load(infile)\n",
    "\n",
    "        total_items = len(data)\n",
    "        print(f\"📊 Total items to convert: {total_items}\")\n",
    "\n",
    "        with open(output_path, 'w', encoding='utf-8') as outfile:\n",
    "            for i, (qid, sample) in enumerate(data.items()):\n",
    "                line_data = {\n",
    "                    \"qid\": qid,\n",
    "                    \"data\": sample\n",
    "                }\n",
    "                outfile.write(json.dumps(line_data, ensure_ascii=False) + '\\n')\n",
    "\n",
    "                if (i + 1) % chunk_size == 0:\n",
    "                    print(f\"📈 Converted {i + 1}/{total_items} items...\")\n",
    "                    # 强制刷新到磁盘\n",
    "                    outfile.flush()\n",
    "\n",
    "        print(f\"✅ Conversion complete! Saved to {output_path}\")\n",
    "\n",
    "        # 清理内存\n",
    "        del data\n",
    "        gc.collect()\n",
    "\n",
    "    def process_jsonl_file(self, jsonl_path: str, output_path: str,\n",
    "                          batch_size: int = 10, save_interval: int = 50):\n",
    "        \"\"\"\n",
    "        流式处理JSONL文件，支持批处理和定期保存\n",
    "        \"\"\"\n",
    "        self.start_time = time.time()\n",
    "        results = {}\n",
    "\n",
    "        # 如果输出文件已存在，加载已处理的结果\n",
    "        if os.path.exists(output_path):\n",
    "            print(\"📂 Loading existing results...\")\n",
    "            with open(output_path, 'r', encoding='utf-8') as f:\n",
    "                results = json.load(f)\n",
    "                self.processed_count = len(results)\n",
    "                print(f\"📊 Loaded {self.processed_count} existing results\")\n",
    "\n",
    "        # 创建输出目录\n",
    "        os.makedirs(os.path.dirname(output_path), exist_ok=True)\n",
    "\n",
    "        with open(jsonl_path, 'r', encoding='utf-8') as f:\n",
    "            batch = []\n",
    "\n",
    "            for line in f:\n",
    "                line_data = json.loads(line.strip())\n",
    "                qid = line_data[\"qid\"]\n",
    "\n",
    "                # 跳过已处理的项目\n",
    "                if qid in results:\n",
    "                    continue\n",
    "\n",
    "                batch.append((qid, line_data[\"data\"]))\n",
    "\n",
    "                # 处理批次\n",
    "                if len(batch) >= batch_size:\n",
    "                    self._process_batch(batch, results)\n",
    "                    batch = []\n",
    "\n",
    "                    # 定期保存和清理内存\n",
    "                    if self.processed_count % save_interval == 0:\n",
    "                        self._save_results(results, output_path)\n",
    "                        gc.collect()\n",
    "                        self._print_progress()\n",
    "\n",
    "            # 处理剩余的项目\n",
    "            if batch:\n",
    "                self._process_batch(batch, results)\n",
    "\n",
    "        # 最终保存\n",
    "        self._save_results(results, output_path)\n",
    "        self._print_final_stats()\n",
    "\n",
    "        return results\n",
    "\n",
    "    def _process_batch(self, batch: list, results: dict):\n",
    "        \"\"\"处理一个批次的数据\"\"\"\n",
    "        for qid, sample in batch:\n",
    "            try:\n",
    "                result = self._process_single_sample(qid, sample)\n",
    "                if result:\n",
    "                    results[qid] = result\n",
    "                    self.processed_count += 1\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"⚠️ Error processing {qid}: {str(e)}\")\n",
    "                self.error_count += 1\n",
    "                continue\n",
    "\n",
    "    def _process_single_sample(self, qid: str, sample: dict) -> dict:\n",
    "        \"\"\"处理单个样本\"\"\"\n",
    "        question = sample[\"question\"]\n",
    "        true_final_result = sample[\"true_final_result\"]\n",
    "\n",
    "        # 找到正样本\n",
    "        correct_sampling_id = None\n",
    "        correct_sample_answer = None\n",
    "\n",
    "        for sampling_id in [\"sampling0\", \"sampling1\", \"sampling2\"]:\n",
    "            if sampling_id not in sample:\n",
    "                continue\n",
    "            if sample[sampling_id][\"final_result\"] == true_final_result:\n",
    "                correct_sampling_id = sampling_id\n",
    "                correct_sample_answer = sample[sampling_id][\"whole_answer\"]\n",
    "                break\n",
    "\n",
    "        if correct_sample_answer is None:\n",
    "            return None\n",
    "\n",
    "        sample_results = {}\n",
    "\n",
    "        # 处理负样本\n",
    "        for sampling_id in [\"sampling0\", \"sampling1\", \"sampling2\"]:\n",
    "            if sampling_id not in sample:\n",
    "                continue\n",
    "            sampling = sample[sampling_id]\n",
    "\n",
    "            # 跳过正样本\n",
    "            if sampling[\"final_result\"] == true_final_result:\n",
    "                continue\n",
    "\n",
    "            incorrect_sample_answer = sampling[\"whole_answer\"]\n",
    "\n",
    "            # 调用API\n",
    "            prompt = build_error_prompt(question, correct_sample_answer, incorrect_sample_answer)\n",
    "            output = call_custom_gpt_api(prompt)\n",
    "\n",
    "            # 解析结果\n",
    "            output = output.strip().strip(\"```\")\n",
    "            if output.startswith(\"json\"):\n",
    "                output = output[4:].strip()\n",
    "\n",
    "            output_json = json.loads(output)\n",
    "\n",
    "            # 查找token索引\n",
    "            error_sentence = output_json[\"first_error_sentence\"]\n",
    "            fix_sentence = output_json[\"fix_sentence\"]\n",
    "\n",
    "            error_token_probs = sample[sampling_id][\"token_probs\"]\n",
    "            correct_token_probs = sample[correct_sampling_id][\"token_probs\"]\n",
    "\n",
    "            error_begin_idx, error_end_idx = find_sentence_span_indices_robust(\n",
    "                error_sentence, error_token_probs\n",
    "            )\n",
    "            fix_begin_idx, fix_end_idx = find_sentence_span_indices_robust(\n",
    "                fix_sentence, correct_token_probs\n",
    "            )\n",
    "\n",
    "            sample_results[sampling_id] = {\n",
    "                \"first_error_sentence\": error_sentence,\n",
    "                \"error_reason\": output_json[\"error_reason\"],\n",
    "                \"fix_sentence\": fix_sentence,\n",
    "                \"fix_reason\": output_json[\"fix_reason\"],\n",
    "                \"correct_sampling_id\": correct_sampling_id,\n",
    "                \"error_token_begin_index\": error_begin_idx,\n",
    "                \"error_token_end_index\": error_end_idx,\n",
    "                \"fix_token_begin_index\": fix_begin_idx,\n",
    "                \"fix_token_end_index\": fix_end_idx\n",
    "            }\n",
    "\n",
    "        return sample_results if sample_results else None\n",
    "\n",
    "    def _save_results(self, results: dict, output_path: str):\n",
    "        \"\"\"保存结果到文件\"\"\"\n",
    "        with open(output_path, 'w', encoding='utf-8') as f:\n",
    "            json.dump(results, f, ensure_ascii=False, indent=2)\n",
    "        print(f\"💾 Saved {len(results)} results to {output_path}\")\n",
    "\n",
    "    def _print_progress(self):\n",
    "        \"\"\"打印进度信息\"\"\"\n",
    "        elapsed = time.time() - self.start_time\n",
    "        speed = self.processed_count / elapsed if elapsed > 0 else 0\n",
    "        print(f\"📊 Progress: {self.processed_count} processed, {self.error_count} errors, \"\n",
    "              f\"{speed:.2f} items/sec, {elapsed:.1f}s elapsed\")\n",
    "\n",
    "    def _print_final_stats(self):\n",
    "        \"\"\"打印最终统计信息\"\"\"\n",
    "        elapsed = time.time() - self.start_time\n",
    "        print(f\"\\n🎉 Processing complete!\")\n",
    "        print(f\"📊 Total processed: {self.processed_count}\")\n",
    "        print(f\"⚠️ Total errors: {self.error_count}\")\n",
    "        print(f\"⏱️ Total time: {elapsed:.1f}s\")\n",
    "        print(f\"🚀 Average speed: {self.processed_count / elapsed:.2f} items/sec\")\n",
    "\n",
    "# 使用示例\n",
    "def main():\n",
    "    # 配置\n",
    "    API_KEY = \"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\"\n",
    "    BASE_PATH = \"/content/drive/MyDrive/Cluster-proj\"\n",
    "    range_tag = \"901-950\"\n",
    "\n",
    "    # 路径设置\n",
    "    input_json = f\"{BASE_PATH}/output/llm_steps/whole_logits/deepseek-math-7b-gsm-{range_tag}.json\"\n",
    "    output_jsonl = f\"{BASE_PATH}/output/llm_steps/whole_logits/deepseek-math-7b-gsm-{range_tag}.jsonl\"\n",
    "    output_results = f\"{BASE_PATH}/output/error_fix_index/deepseek-math-7b-{range_tag}_error_fix_index.json\"\n",
    "\n",
    "    # 创建处理器\n",
    "    processor = JSONLProcessor(API_KEY)\n",
    "\n",
    "    # 步骤1: 转换为JSONL（如果还没有转换）\n",
    "    if not os.path.exists(output_jsonl):\n",
    "        processor.convert_json_to_jsonl(input_json, output_jsonl)\n",
    "    else:\n",
    "        print(f\"📂 JSONL file already exists: {output_jsonl}\")\n",
    "\n",
    "    # 步骤2: 处理JSONL文件\n",
    "    print(\"\\n🚀 Starting JSONL processing...\")\n",
    "    results = processor.process_jsonl_file(\n",
    "        jsonl_path=output_jsonl,\n",
    "        output_path=output_results,\n",
    "        batch_size=5,      # 减小批次大小以节省内存\n",
    "        save_interval=20   # 每20个项目保存一次\n",
    "    )\n",
    "\n",
    "    print(f\"\\n✅ All processing complete! Results saved to {output_results}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "395ibCrtWL9g"
   },
   "outputs": [],
   "source": [
    "\n",
    "import json\n",
    "import os\n",
    "import requests\n",
    "from difflib import SequenceMatcher\n",
    "import re\n",
    "\n",
    "\n",
    "# ✅ Your custom API config\n",
    "API_KEY = \"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\"\n",
    "MODEL = \"gpt-4.1\"\n",
    "\n",
    "# ✅ Paths\n",
    "start_index = 901\n",
    "end_index = 950\n",
    "range_tag = f\"{start_index}-{end_index}\"\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 17615,
     "status": "ok",
     "timestamp": 1752385599756,
     "user": {
      "displayName": "Tingting Du",
      "userId": "01262363838823204487"
     },
     "user_tz": -480
    },
    "id": "csyUtLNuTHGH",
    "outputId": "165775b8-e0e2-4420-ae86-528c9e9d77db"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1752385608551,
     "user": {
      "displayName": "Tingting Du",
      "userId": "01262363838823204487"
     },
     "user_tz": -480
    },
    "id": "zd7vIS3qv6rH"
   },
   "outputs": [],
   "source": [
    "\n",
    "BASE_PATH = \"/content/drive/MyDrive/Cluster-proj\"\n",
    "LOGITS_PATH = f\"{BASE_PATH}/output/llm_steps/whole_logits/deepseek-math-7b-gsm-{range_tag}.json\"\n",
    "\n",
    "# ✅ Prompt builder\n",
    "def build_error_prompt(question, true_whole_answer, sample_whole_answer):\n",
    "    return f\"\"\"\n",
    "Here is a math problem, its correct answer, and a sample answer that may contain mistakes.\n",
    "\n",
    "【Question】:\n",
    "{question}\n",
    "\n",
    "【Correct Answer】:\n",
    "{true_whole_answer}\n",
    "\n",
    "【Incorrect Answer】:\n",
    "{sample_whole_answer}\n",
    "\n",
    "Please help me:\n",
    "1. Identify the earliest mistake in the incorrect answer and provide the compelete sentence from that point.\n",
    "2. Briefly explain why it is incorrect.\n",
    "3. Find the fix sentence in correct answer that and fix the error.\n",
    "4. Briefly explain why it can fix the error.\n",
    "\n",
    "Please output in the following JSON format:\n",
    "{{\n",
    "  \"first_error_sentence\": \"<sentence>\",\n",
    "  \"error_reason\": \"<brief explanation>\",\n",
    "  \"fix_sentence\": \"<sentence>\",\n",
    "  \"fix_reason\": \"<brief explanation>\"\n",
    "}}\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "# ✅ Call your custom GPT API\n",
    "def call_custom_gpt_api(prompt):\n",
    "    headers = {\n",
    "        \"Authorization\": f\"Bearer {API_KEY}\",\n",
    "        \"Content-Type\": \"application/json\"\n",
    "    }\n",
    "    payload = {\n",
    "        \"model\": MODEL,\n",
    "        \"messages\": [\n",
    "            {\"role\": \"system\", \"content\": \"You are a meticulous and precise comparer.\"},\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ]\n",
    "    }\n",
    "    response = requests.post(\n",
    "        \"https://api.openai.com/v1/chat/completions\",\n",
    "        headers=headers,\n",
    "        json=payload\n",
    "    )\n",
    "    if response.status_code != 200:\n",
    "        raise Exception(f\"API request failed: {response.status_code}, {response.text}\")\n",
    "    return response.json()[\"choices\"][0][\"message\"][\"content\"]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1752385611071,
     "user": {
      "displayName": "Tingting Du",
      "userId": "01262363838823204487"
     },
     "user_tz": -480
    },
    "id": "kArxmbIiyzEo"
   },
   "outputs": [],
   "source": [
    "import re\n",
    "# ✅ 匹配函数：返回片段起止 token index\n",
    "def find_sentence_span_indices_robust(fragment, token_probs):\n",
    "    \"\"\"\n",
    "    返回 fragment 在 token_probs 中匹配到的 token 范围: (begin_index, end_index)\n",
    "    - 使用去除空白字符的方式匹配\n",
    "    \"\"\"\n",
    "    fragment_clean = re.sub(r\"\\s+\", \"\", fragment)\n",
    "    tokens = [entry[\"token\"] for entry in token_probs]\n",
    "    decoded_text = \"\".join(tokens)\n",
    "    decoded_text_clean = re.sub(r\"\\s+\", \"\", decoded_text)\n",
    "\n",
    "    char_start_idx = decoded_text_clean.find(fragment_clean)\n",
    "    if char_start_idx == -1:\n",
    "        return -1, -1\n",
    "\n",
    "    cumulative_len = 0\n",
    "    begin_index = -1\n",
    "    for idx, entry in enumerate(token_probs):\n",
    "        token_clean = re.sub(r\"\\s+\", \"\", entry[\"token\"])\n",
    "        prev_len = cumulative_len\n",
    "        cumulative_len += len(token_clean)\n",
    "\n",
    "        if begin_index == -1 and cumulative_len > char_start_idx:\n",
    "            begin_index = idx\n",
    "        if cumulative_len >= char_start_idx + len(fragment_clean):\n",
    "            end_index = idx\n",
    "            return begin_index, end_index\n",
    "\n",
    "    return begin_index, len(token_probs) - 1  # fallback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 435,
     "status": "ok",
     "timestamp": 1752385892968,
     "user": {
      "displayName": "Tingting Du",
      "userId": "01262363838823204487"
     },
     "user_tz": -480
    },
    "id": "hcE4714PVqjA",
    "outputId": "83fad770-27a4-430c-9c45-4d54a2168ae5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting up swapspace version 1, size = 4 GiB (4294963200 bytes)\n",
      "no label, UUID=0082653d-b97c-4cd0-9b1e-a8ce020a3a7e\n",
      "swapon: /tmp/swapfile: swapon failed: Invalid argument\n"
     ]
    }
   ],
   "source": [
    "!fallocate -l 4G /tmp/swapfile\n",
    "!chmod 600 /tmp/swapfile\n",
    "!mkswap /tmp/swapfile\n",
    "!swapon /tmp/swapfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VivaNj7IvaWo"
   },
   "outputs": [],
   "source": [
    "\n",
    "# ✅ Load logits_data\n",
    "with open(LOGITS_PATH, \"r\") as f:\n",
    "    logits_data = json.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VyVrVVLATnxN"
   },
   "outputs": [],
   "source": [
    "\n",
    "results = {}\n",
    "\n",
    "# ✅ 主循环 - 修改为比较正负样本\n",
    "for qid, sample in logits_data.items():\n",
    "    question = sample[\"question\"]\n",
    "    true_final_result = sample[\"true_final_result\"]\n",
    "\n",
    "    # 找到正样本（正确的sampling）\n",
    "    correct_sampling_id = None\n",
    "    correct_sample_answer = None\n",
    "\n",
    "    for sampling_id in [\"sampling0\", \"sampling1\", \"sampling2\"]:\n",
    "        if sampling_id not in sample:\n",
    "            continue\n",
    "        if sample[sampling_id][\"final_result\"] == true_final_result:\n",
    "            correct_sampling_id = sampling_id\n",
    "            correct_sample_answer = sample[sampling_id][\"whole_answer\"]\n",
    "            break\n",
    "\n",
    "    # 如果没有找到正样本，跳过这个问题\n",
    "    if correct_sample_answer is None:\n",
    "        print(f\"⚠️ No correct sampling found for {qid}, skipping...\")\n",
    "        continue\n",
    "\n",
    "    # 处理负样本（错误的sampling）\n",
    "    for sampling_id in [\"sampling0\", \"sampling1\", \"sampling2\"]:\n",
    "        if sampling_id not in sample:\n",
    "            continue\n",
    "        sampling = sample[sampling_id]\n",
    "\n",
    "        # 跳过正样本\n",
    "        if sampling[\"final_result\"] == true_final_result:\n",
    "            continue\n",
    "\n",
    "        incorrect_sample_answer = sampling[\"whole_answer\"]\n",
    "\n",
    "        # 构造 prompt 并调用 API - 使用正样本作为正确答案\n",
    "        prompt = build_error_prompt(question, correct_sample_answer, incorrect_sample_answer)\n",
    "        output = call_custom_gpt_api(prompt)\n",
    "        print(f\"\\n🔍 {qid} / {sampling_id} (comparing with {correct_sampling_id}):\\n{output}\")\n",
    "\n",
    "        # 去除可能的 ''' 包裹\n",
    "        output = output.strip().strip(\"```\")\n",
    "        if output.startswith(\"json\"):\n",
    "            output = output[4:].strip()\n",
    "\n",
    "        # 解析 JSON\n",
    "        try:\n",
    "            output_json = json.loads(output)\n",
    "            error_sentence = output_json[\"first_error_sentence\"]\n",
    "            error_reason = output_json[\"error_reason\"]\n",
    "            fix_sentence = output_json[\"fix_sentence\"]\n",
    "            fix_reason = output_json[\"fix_reason\"]\n",
    "        except Exception as e:\n",
    "            print(f\"⚠️ JSON parsing failed: {e}\")\n",
    "            error_sentence = \"\"\n",
    "            error_reason = output\n",
    "            fix_sentence = \"\"\n",
    "            fix_reason = \"\"\n",
    "\n",
    "        # ✅ 保存结果\n",
    "        if qid not in results:\n",
    "            results[qid] = {}\n",
    "        results[qid][sampling_id] = {\n",
    "            \"first_error_sentence\": error_sentence,\n",
    "            \"error_reason\": error_reason,\n",
    "            \"fix_sentence\": fix_sentence,\n",
    "            \"fix_reason\": fix_reason,\n",
    "            \"correct_sampling_id\": correct_sampling_id  # 记录使用的正样本ID\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PO1s4NmFTpnx"
   },
   "outputs": [],
   "source": [
    "\n",
    "# ✅ 第二轮遍历，补充 token index\n",
    "for qid, sample_data in results.items():\n",
    "    for sampling_id, info in sample_data.items():\n",
    "        error_sentence = info[\"first_error_sentence\"]\n",
    "        fix_sentence = info[\"fix_sentence\"]\n",
    "        correct_sampling_id = info[\"correct_sampling_id\"]\n",
    "\n",
    "        # 获取错误样本的token_probs\n",
    "        error_token_probs = logits_data[qid][sampling_id][\"token_probs\"]\n",
    "\n",
    "        # 匹配错误句子的 token index 范围\n",
    "        error_begin_idx, error_end_idx = find_sentence_span_indices_robust(error_sentence, error_token_probs)\n",
    "\n",
    "        # 获取正确样本的token_probs\n",
    "        correct_token_probs = logits_data[qid][correct_sampling_id][\"token_probs\"]\n",
    "\n",
    "        # 匹配修复句子的 token index 范围\n",
    "        fix_begin_idx, fix_end_idx = find_sentence_span_indices_robust(fix_sentence, correct_token_probs)\n",
    "\n",
    "        # 加入到结果中\n",
    "        info[\"error_token_begin_index\"] = error_begin_idx\n",
    "        info[\"error_token_end_index\"] = error_end_idx\n",
    "        info[\"fix_token_begin_index\"] = fix_begin_idx\n",
    "        info[\"fix_token_end_index\"] = fix_end_idx\n",
    "\n",
    "        # 可选：打印检查\n",
    "        print(f\"{qid} / {sampling_id}:\")\n",
    "        print(f\"  Error: [{error_begin_idx}, {error_end_idx}] : {error_sentence}\")\n",
    "        print(f\"  Fix (from {correct_sampling_id}): [{fix_begin_idx}, {fix_end_idx}] : {fix_sentence}\")\n",
    "\n",
    "# ✅ 保存结果\n",
    "output_dir = os.path.join(BASE_PATH, \"output/error_fix_index\")\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "output_path = os.path.join(output_dir, f\"deepseek-math-7b-{range_tag}_error_fix_index.json\")\n",
    "with open(output_path, \"w\") as f:\n",
    "    json.dump(results, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "print(f\"\\n✅ 所有结果已保存到 {output_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "r9qVXoMsTq_t"
   },
   "outputs": [],
   "source": [
    "\n",
    "# ✅ 验证部分 - 修改为验证错误句子和修复句子\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"开始验证...\")\n",
    "\n",
    "for qid, sample_data in results.items():\n",
    "    for sampling_id, info in sample_data.items():\n",
    "        error_sentence = info.get(\"first_error_sentence\", \"\").strip()\n",
    "        error_start = info.get(\"error_token_begin_index\", -1)\n",
    "        error_end = info.get(\"error_token_end_index\", -1)\n",
    "\n",
    "        fix_sentence = info.get(\"fix_sentence\", \"\").strip()\n",
    "        fix_start = info.get(\"fix_token_begin_index\", -1)\n",
    "        fix_end = info.get(\"fix_token_end_index\", -1)\n",
    "\n",
    "        correct_sampling_id = info.get(\"correct_sampling_id\", \"\")\n",
    "\n",
    "        # 验证错误句子\n",
    "        if error_start != -1 and error_end != -1:\n",
    "            error_token_probs = logits_data[qid][sampling_id][\"token_probs\"]\n",
    "            error_tokens = [entry[\"token\"] for entry in error_token_probs[error_start:error_end+1]]\n",
    "            error_reconstructed = \" \".join(error_tokens).strip()\n",
    "\n",
    "            print(\"=\" * 60)\n",
    "            print(f\"🔍 {qid} / {sampling_id}\")\n",
    "            print(f\"📌 Error token span [{error_start}, {error_end}]:\\n{error_reconstructed}\")\n",
    "            print(f\"📌 Error sentence:\\n{error_sentence}\")\n",
    "\n",
    "            error_clean = re.sub(r\"\\s+\", \"\", error_reconstructed.lower())\n",
    "            error_sentence_clean = re.sub(r\"\\s+\", \"\", error_sentence.lower())\n",
    "            error_match = \"✅ MATCH\" if error_clean == error_sentence_clean else \"❌ DIFFERENT\"\n",
    "            print(f\"🔎 Error比对结果: {error_match}\")\n",
    "\n",
    "        # 验证修复句子\n",
    "        if fix_start != -1 and fix_end != -1:\n",
    "            correct_token_probs = logits_data[qid][correct_sampling_id][\"token_probs\"]\n",
    "            fix_tokens = [entry[\"token\"] for entry in correct_token_probs[fix_start:fix_end+1]]\n",
    "            fix_reconstructed = \" \".join(fix_tokens).strip()\n",
    "\n",
    "            print(f\"\\n📌 Fix token span (from {correct_sampling_id}) [{fix_start}, {fix_end}]:\\n{fix_reconstructed}\")\n",
    "            print(f\"📌 Fix sentence:\\n{fix_sentence}\")\n",
    "\n",
    "            fix_clean = re.sub(r\"\\s+\", \"\", fix_reconstructed.lower())\n",
    "            fix_sentence_clean = re.sub(r\"\\s+\", \"\", fix_sentence.lower())\n",
    "            fix_match = \"✅ MATCH\" if fix_clean == fix_sentence_clean else \"❌ DIFFERENT\"\n",
    "            print(f\"🔎 Fix比对结果: {fix_match}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QnM5ucqEWSFa"
   },
   "outputs": [],
   "source": [
    "#version 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 216
    },
    "executionInfo": {
     "elapsed": 68,
     "status": "error",
     "timestamp": 1752386044311,
     "user": {
      "displayName": "Tingting Du",
      "userId": "01262363838823204487"
     },
     "user_tz": -480
    },
    "id": "SFgdVELt0y2b",
    "outputId": "e3de0332-bcf9-49b7-8b1b-3e3622bde60c"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'logits_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipython-input-2-3590688224.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# ✅ 主循环\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mqid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlogits_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mquestion\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msample\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"question\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mtrue_final_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msample\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"true_final_result\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'logits_data' is not defined"
     ]
    }
   ],
   "source": [
    "results = {}\n",
    "\n",
    "# ✅ 主循环\n",
    "for qid, sample in logits_data.items():\n",
    "    question = sample[\"question\"]\n",
    "    true_final_result = sample[\"true_final_result\"]\n",
    "    # true_whole_answer = sample[\"true_whole_answer\"]\n",
    "\n",
    "    for sampling_id in [\"sampling0\", \"sampling1\", \"sampling2\"]:\n",
    "        if sampling_id not in sample:\n",
    "            continue\n",
    "        sampling = sample[sampling_id]\n",
    "        if sampling[\"final_result\"] == true_final_result:\n",
    "            true_whole_answer = sampling[\"whole_answer\"]\n",
    "\n",
    "        sample_whole_answer = sampling[\"whole_answer\"]\n",
    "\n",
    "        # 构造 prompt 并调用 API\n",
    "        prompt = build_error_prompt(question, true_whole_answer, sample_whole_answer)\n",
    "        output = call_custom_gpt_api(prompt)\n",
    "        print(f\"\\n🔍 {qid} / {sampling_id}:\\n{output}\")\n",
    "\n",
    "        # 去除可能的 ''' 包裹\n",
    "        output = output.strip().strip(\"\")\n",
    "        if output.startswith(\"json\"):\n",
    "          output = output[4:].strip()\n",
    "        # 解析 JSON\n",
    "        try:\n",
    "            output_json = json.loads(output)\n",
    "            sentence = output_json[\"first_error_sentence\"]\n",
    "            error_reason = output_json[\"error_reason\"]\n",
    "        except Exception as e:\n",
    "            print(f\"⚠️ JSON parsing failed: {e}\")\n",
    "            sentence = \"\"\n",
    "            error_reason = output\n",
    "\n",
    "        # ✅ 保存结果（字段名为 sentence）\n",
    "        if qid not in results:\n",
    "            results[qid] = {}\n",
    "        results[qid][sampling_id] = {\n",
    "            \"first_error_sentence\": sentence,\n",
    "            \"error_reason\": error_reason,\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 42,
     "status": "ok",
     "timestamp": 1752386044376,
     "user": {
      "displayName": "Tingting Du",
      "userId": "01262363838823204487"
     },
     "user_tz": -480
    },
    "id": "-rzUgTjDvZW2"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# ✅ 第二轮遍历，补充 token index（不重新调用 API）\n",
    "for qid, sample_data in results.items():\n",
    "    for sampling_id, info in sample_data.items():\n",
    "        sentence = info[\"first_error_sentence\"]\n",
    "        token_probs = logits_data[qid][sampling_id][\"token_probs\"]\n",
    "\n",
    "        # 匹配 token index 范围\n",
    "        begin_idx, end_idx = find_sentence_span_indices_robust(sentence, token_probs)\n",
    "\n",
    "        # 加入到结果中\n",
    "        info[\"first_error_token_index\"] = begin_idx\n",
    "        info[\"last_error_token_index\"] = end_idx\n",
    "\n",
    "        # 可选：打印检查\n",
    "        print(f\"{qid} / {sampling_id} → [{begin_idx}, {end_idx}] : {sentence}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 22,
     "status": "ok",
     "timestamp": 1752318406170,
     "user": {
      "displayName": "Tingting Du",
      "userId": "01262363838823204487"
     },
     "user_tz": -480
    },
    "id": "r5s9ar40087_",
    "outputId": "1e62a26f-071f-400c-a71c-df052641eca8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ 所有结果已保存到 /content/drive/MyDrive/Cluster-proj/output/error_index/deepseek-math-7b-901-950_index.json\n"
     ]
    }
   ],
   "source": [
    "output_dir = os.path.join(BASE_PATH, \"output/error_index\")\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "output_path = os.path.join(output_dir, f\"deepseek-math-7b-{range_tag}_index.json\")\n",
    "with open(output_path, \"w\") as f:\n",
    "    json.dump(results, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "print(f\"\\n✅ 所有结果已保存到 {output_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1752318668660,
     "user": {
      "displayName": "Tingting Du",
      "userId": "01262363838823204487"
     },
     "user_tz": -480
    },
    "id": "TJo4IlCJVNzi",
    "outputId": "7aef6f02-a7bc-49c2-819b-3e908f350525"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['question', 'true_whole_answer', 'true_final_result', 'sampling0', 'sampling1', 'sampling2'])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#test\n",
    "logits_data['q_947'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "executionInfo": {
     "elapsed": 14,
     "status": "ok",
     "timestamp": 1752319077529,
     "user": {
      "displayName": "Tingting Du",
      "userId": "01262363838823204487"
     },
     "user_tz": -480
    },
    "id": "KQ9kOdCfVPqB",
    "outputId": "77515932-f71b-4be8-fbe7-a87b9c6cb6cf"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'31'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#test\n",
    "logits_data['q_927']['true_final_result']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "executionInfo": {
     "elapsed": 17,
     "status": "ok",
     "timestamp": 1752319096785,
     "user": {
      "displayName": "Tingting Du",
      "userId": "01262363838823204487"
     },
     "user_tz": -480
    },
    "id": "b7d33zosVUVN",
    "outputId": "06e8a2a1-6ced-443e-833f-c6ad0b0f0144"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'50'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#test\n",
    "logits_data['q_927']['sampling2']['final_result']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 176,
     "status": "ok",
     "timestamp": 1752318455467,
     "user": {
      "displayName": "Tingting Du",
      "userId": "01262363838823204487"
     },
     "user_tz": -480
    },
    "id": "viclNJ79EZF5",
    "outputId": "ea17c979-4c28-4438-ee46-e2de862d2b5a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "🔍 q_902 / sampling0\n",
      "📌 Token span [36, 74]:\n",
      "He fed an equal number of straw s to the pig lets , which means he fed  1 8 0 straw s /  2 0 pig lets =  9 straw s to each pig let .\n",
      "\n",
      "📌 Error sentence:\n",
      "He fed an equal number of straws to the piglets, which means he fed 180 straws / 20 piglets = 9 straws to each piglet.\n",
      "\n",
      "🔎 比对结果: ✅ MATCH\n",
      "\n",
      "============================================================\n",
      "🔍 q_906 / sampling2\n",
      "📌 Token span [34, 56]:\n",
      "At the second stop ,  3 people got off the bus , so the number of passengers decreased by  3 .\n",
      "\n",
      "📌 Error sentence:\n",
      "At the second stop, 3 people got off the bus, so the number of passengers decreased by 3.\n",
      "\n",
      "🔎 比对结果: ✅ MATCH\n",
      "\n",
      "============================================================\n",
      "🔍 q_911 / sampling0\n",
      "📌 Token span [136, 182]:\n",
      "Now , to find the combined time the all igators walked , we need to add the time Paul spent walking to the Nile Delta ( 4 hours ) and the time the other six all igators spent walking on the return journey ( 6 hours ).\n",
      "\n",
      "📌 Error sentence:\n",
      "Now, to find the combined time the alligators walked, we need to add the time Paul spent walking to the Nile Delta (4 hours) and the time the other six alligators spent walking on the return journey (6 hours).\n",
      "\n",
      "🔎 比对结果: ✅ MATCH\n",
      "\n",
      "============================================================\n",
      "🔍 q_911 / sampling1\n",
      "📌 Token span [117, 183]:\n",
      "3 . The total time the all igators walked is the sum of the time it took for Paul to walk to the Nile Delta and the time it took for Paul and the other six all igators to travel from the Nile Delta to their home . So , the total time is  4 hours +  6 hours =  1 0 hours .\n",
      "\n",
      "📌 Error sentence:\n",
      "3. The total time the alligators walked is the sum of the time it took for Paul to walk to the Nile Delta and the time it took for Paul and the other six alligators to travel from the Nile Delta to their home. So, the total time is 4 hours + 6 hours = 10 hours.\n",
      "\n",
      "🔎 比对结果: ✅ MATCH\n",
      "\n",
      "============================================================\n",
      "🔍 q_911 / sampling2\n",
      "📌 Token span [168, 197]:\n",
      "Now , to find the total time the all igators walked , we add the time it took for the journey to the Nile Delta and the return journey .\n",
      "\n",
      "📌 Error sentence:\n",
      "Now, to find the total time the alligators walked, we add the time it took for the journey to the Nile Delta and the return journey.\n",
      "\n",
      "🔎 比对结果: ✅ MATCH\n",
      "\n",
      "============================================================\n",
      "🔍 q_912 / sampling0\n",
      "📌 Token span [176, 235]:\n",
      "So , they can make  1 6 /  7 =  2 jars of jam from Betty ' s strawberries ,  3 6 /  7 =  5 jars of jam from Matthew ' s strawberries , and  1 8 /  7 =  2 jars of jam from Natalie ' s strawberries .\n",
      "\n",
      "📌 Error sentence:\n",
      "So, they can make 16 / 7 = 2 jars of jam from Betty's strawberries, 36 / 7 = 5 jars of jam from Matthew's strawberries, and 18 / 7 = 2 jars of jam from Natalie's strawberries.\n",
      "\n",
      "🔎 比对结果: ✅ MATCH\n",
      "\n",
      "============================================================\n",
      "🔍 q_919 / sampling0\n",
      "📌 Token span [47, 75]:\n",
      "She then adds twice the amount she already had , so she adds  2 *  1 0 0 0 =  2 0 0 0 songs .\n",
      "\n",
      "📌 Error sentence:\n",
      "She then adds twice the amount she already had, so she adds 2 * 1000 = 2000 songs.\n",
      "\n",
      "🔎 比对结果: ✅ MATCH\n",
      "\n",
      "============================================================\n",
      "🔍 q_919 / sampling1\n",
      "📌 Token span [50, 82]:\n",
      "She then adds twice the amount she already had on her mp 3 player , which is  2 *  1 0 0 0 =  2 0 0 0 songs .\n",
      "\n",
      "📌 Error sentence:\n",
      "She then adds twice the amount she already had on her mp3 player, which is 2 * 1000 = 2000 songs.\n",
      "\n",
      "🔎 比对结果: ✅ MATCH\n",
      "\n",
      "============================================================\n",
      "🔍 q_919 / sampling2\n",
      "📌 Token span [47, 74]:\n",
      "She then adds twice the amount she already had , which is  2 *  1 0 0 0 =  2 0 0 0 songs .\n",
      "\n",
      "📌 Error sentence:\n",
      "She then adds twice the amount she already had, which is 2 * 1000 = 2000 songs.\n",
      "\n",
      "🔎 比对结果: ✅ MATCH\n",
      "\n",
      "============================================================\n",
      "🔍 q_922 / sampling0\n",
      "📌 Token span [101, 122]:\n",
      "In the new company , she ' s earned  2 0 % more than she earned at the old company .\n",
      "\n",
      "📌 Error sentence:\n",
      "In the new company, she's earned 20% more than she earned at the old company.\n",
      "\n",
      "🔎 比对结果: ✅ MATCH\n",
      "\n",
      "============================================================\n",
      "🔍 q_927 / sampling0\n",
      "📌 Token span [21, 49]:\n",
      "So , each friend invited one person , making the total number of guests Ashley had initially  2 0 +  2 0 =  4 0 .\n",
      "\n",
      "📌 Error sentence:\n",
      "So, each friend invited one person, making the total number of guests Ashley had initially 20 + 20 = 40.\n",
      "\n",
      "🔎 比对结果: ✅ MATCH\n",
      "\n",
      "============================================================\n",
      "🔍 q_927 / sampling1\n",
      "📌 Token span [23, 56]:\n",
      "So , each of the  2 0 friends brought one more person , which means there were  2 0 *  1 =  2 0 additional people at the party .\n",
      "\n",
      "📌 Error sentence:\n",
      "So, each of the 20 friends brought one more person, which means there were 20 * 1 = 20 additional people at the party.\n",
      "\n",
      "🔎 比对结果: ✅ MATCH\n",
      "\n",
      "============================================================\n",
      "🔍 q_927 / sampling2\n",
      "📌 Token span [75, 123]:\n",
      "Therefore , the total number of people at the party , including Ashley , is  2 0 ( Ash ley ) +  2 0 ( her friends ) +  1 0 ( the extra people brought by her friends ) =  5 0 people .\n",
      "\n",
      "📌 Error sentence:\n",
      "Therefore, the total number of people at the party, including Ashley, is 20 (Ashley) + 20 (her friends) + 10 (the extra people brought by her friends) = 50 people.\n",
      "\n",
      "🔎 比对结果: ✅ MATCH\n",
      "\n",
      "============================================================\n",
      "🔍 q_943 / sampling1\n",
      "📌 Token span [96, 122]:\n",
      "He wants to reach a goal of $ 9 6 , so we can set up the equation  1 2 D =  9 6 .\n",
      "\n",
      "📌 Error sentence:\n",
      "He wants to reach a goal of $96, so we can set up the equation 12D = 96.\n",
      "\n",
      "🔎 比对结果: ✅ MATCH\n",
      "\n",
      "============================================================\n",
      "🔍 q_947 / sampling0\n",
      "📌 Token span [33, 49]:\n",
      "This means that in  2 0 days , he will have doubled his current practice .\n",
      "\n",
      "📌 Error sentence:\n",
      "This means that in 20 days, he will have doubled his current practice.\n",
      "\n",
      "🔎 比对结果: ✅ MATCH\n",
      "\n",
      "============================================================\n",
      "🔍 q_947 / sampling1\n",
      "📌 Token span [63, 78]:\n",
      "This means that Johnny has done  1 0 days worth of practice so far .\n",
      "\n",
      "📌 Error sentence:\n",
      "This means that Johnny has done 10 days worth of practice so far.\n",
      "\n",
      "🔎 比对结果: ✅ MATCH\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#check\n",
    "\n",
    "\n",
    "import json\n",
    "import os\n",
    "import re\n",
    "\n",
    "# ✅ 路径配置\n",
    "BASE_PATH = \"/content/drive/MyDrive/Cluster-proj\"\n",
    "range_tag = \"901-950\"\n",
    "LOGITS_PATH = f\"{BASE_PATH}/output/llm_steps/whole_logits/deepseek7b-gsm-{range_tag}.json\"\n",
    "ERROR_INDEX_PATH = f\"{BASE_PATH}/output/error_index/deepseek-math-7b-{range_tag}_index.json\"\n",
    "\n",
    "# # ✅ 加载两个数据源\n",
    "# with open(LOGITS_PATH, \"r\") as f:\n",
    "#     logits_data = json.load(f)\n",
    "\n",
    "with open(ERROR_INDEX_PATH, \"r\") as f:\n",
    "    error_index_data = json.load(f)\n",
    "\n",
    "# ✅ 遍历每一条，拼接 token & 比对句子\n",
    "for qid, sample_data in error_index_data.items():\n",
    "    for sampling_id, info in sample_data.items():\n",
    "        sentence = info.get(\"first_error_sentence\", \"\").strip()\n",
    "        start = info.get(\"first_error_token_index\", -1)\n",
    "        end = info.get(\"last_error_token_index\", -1)\n",
    "\n",
    "        if start == -1 or end == -1:\n",
    "            print(f\"{qid} / {sampling_id} ❌ 缺失 index\")\n",
    "            continue\n",
    "\n",
    "        token_probs = logits_data[qid][sampling_id][\"token_probs\"]\n",
    "        tokens = [entry[\"token\"] for entry in token_probs[start:end+1]]\n",
    "        reconstructed = \" \".join(tokens).strip()\n",
    "\n",
    "        print(\"=\" * 60)\n",
    "        print(f\"🔍 {qid} / {sampling_id}\")\n",
    "        print(f\"📌 Token span [{start}, {end}]:\\n{reconstructed}\")\n",
    "        print(f\"\\n📌 Error sentence:\\n{sentence}\")\n",
    "\n",
    "        # 简单比对相似度\n",
    "        reconstructed_clean = re.sub(r\"\\s+\", \"\", reconstructed.lower())\n",
    "        sentence_clean = re.sub(r\"\\s+\", \"\", sentence.lower())\n",
    "        match_status = \"✅ MATCH\" if reconstructed_clean == sentence_clean else \"❌ DIFFERENT\"\n",
    "\n",
    "        print(f\"\\n🔎 比对结果: {match_status}\\n\")\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyMQPNedmW8IUavg3TIqI+SP",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "cluster",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

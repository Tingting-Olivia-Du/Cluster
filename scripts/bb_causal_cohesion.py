# -*- coding: utf-8 -*-
"""
Causal Judgment Cluster Cohesion Analysis (Sample-wise)
åˆ†æå› æœåˆ¤æ–­ä»»åŠ¡ä¸­æ­£è´Ÿæ ·æœ¬çš„èšç±»å†…èšåº¦ç‰¹å¾ - æ ·æœ¬çº§åˆ«åˆ†æ
"""

import os
import json
import numpy as np
import matplotlib.pyplot as plt
from sklearn.cluster import KMeans
from sklearn.metrics import silhouette_score
import warnings
warnings.filterwarnings('ignore')

# ============================================================================
# CONFIGURATION
# ============================================================================

# æœ¬åœ°ç›¸å¯¹è·¯å¾„é…ç½®
INPUT_PATH = "./logits/bb_causal_judgment_experiment_26-50.json"
OUTPUT_DIR = "./output/bb_26-50_causal_judgment_analysis"
VISUALIZATION_DIR = f"{OUTPUT_DIR}/visualizations"

# Create directories
os.makedirs(OUTPUT_DIR, exist_ok=True)
os.makedirs(VISUALIZATION_DIR, exist_ok=True)

print("ğŸš€ Starting Causal Judgment Cluster Cohesion Analysis (Sample-wise)...")
print(f"ğŸ“‚ Input path: {INPUT_PATH}")
print(f"ğŸ“ Output directory: {OUTPUT_DIR}")

# ============================================================================
# DATA LOADING AND HELPER FUNCTIONS
# ============================================================================

def load_causal_judgment_data(file_path):
    """åŠ è½½å› æœåˆ¤æ–­å®éªŒæ•°æ®"""
    print(f"ğŸ”„ Attempting to load data from: {os.path.abspath(file_path)}")
    
    if not os.path.exists(file_path):
        print(f"âŒ File not found: {file_path}")
        print("ğŸ“ Current working directory:", os.getcwd())
        print("ğŸ“‚ Available files in current directory:")
        try:
            for item in os.listdir("."):
                if os.path.isfile(item):
                    print(f"   ğŸ“„ {item}")
                elif os.path.isdir(item):
                    print(f"   ğŸ“ {item}/")
        except:
            pass
        return None
    
    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            data = json.load(f)
        print(f"âœ… Successfully loaded data with {len(data.get('results', {}))} questions")
        return data
    except json.JSONDecodeError as e:
        print(f"âŒ Error decoding JSON: {e}")
        return None
    except Exception as e:
        print(f"âŒ Error loading file: {e}")
        return None

def compute_cluster_cohesion(vectors):
    """
    è®¡ç®—å‘é‡é›†åˆçš„èšç±»å†…èšåº¦
    
    Args:
        vectors: list of hidden vectors
        
    Returns:
        dict: cluster cohesion metrics
    """
    if not vectors or len(vectors) < 2:
        return {
            'cluster_cohesion': 0.0,
            'optimal_clusters': 1,
            'min_inertia': 0.0,
            'best_silhouette_score': 0.0,
            'n_tokens': len(vectors) if vectors else 0
        }
    
    vectors = np.array(vectors)
    n_tokens = len(vectors)
    
    # è®¡ç®—è´¨å¿ƒ
    centroid = np.mean(vectors, axis=0)
    
    # åŸºç¡€åº¦é‡
    centroid_distances = [np.linalg.norm(vec - centroid) for vec in vectors]
    
    # K-meansèšç±»åˆ†æ
    max_clusters = min(5, n_tokens)
    inertias = []
    silhouette_scores = []
    
    for k in range(1, max_clusters + 1):
        if k == 1:
            # å•ä¸ªèšç±»çš„æƒ¯æ€§
            inertia = np.sum([np.linalg.norm(vec - centroid) ** 2 for vec in vectors])
            inertias.append(inertia)
            silhouette_scores.append(0.0)
        else:
            try:
                kmeans = KMeans(n_clusters=k, random_state=42, n_init=10)
                labels = kmeans.fit_predict(vectors)
                inertias.append(kmeans.inertia_)
                
                # è®¡ç®—è½®å»“ç³»æ•°
                if len(set(labels)) > 1:
                    sil_score = silhouette_score(vectors, labels)
                    silhouette_scores.append(sil_score)
                else:
                    silhouette_scores.append(0.0)
            except:
                inertias.append(inertias[-1] if inertias else 0.0)
                silhouette_scores.append(0.0)
    
    # æœ€ä½³æŒ‡æ ‡
    best_silhouette_score = float(np.max(silhouette_scores))
    optimal_clusters = int(np.argmax(silhouette_scores) + 1)
    min_inertia = float(np.min(inertias))
    
    # èšç±»å†…èšåº¦ = 1 / (1 + æœ€å°æƒ¯æ€§)
    cluster_cohesion = float(1 / (1 + min_inertia))
    
    return {
        'cluster_cohesion': cluster_cohesion,
        'optimal_clusters': optimal_clusters,
        'min_inertia': min_inertia,
        'best_silhouette_score': best_silhouette_score,
        'n_tokens': n_tokens,
        'centroid_distance_mean': float(np.mean(centroid_distances)),
        'centroid_distance_std': float(np.std(centroid_distances))
    }

# ============================================================================
# MAIN ANALYSIS FUNCTIONS
# ============================================================================

def extract_positive_negative_pairs(data):
    """æå–æ­£è´Ÿæ ·æœ¬å¯¹"""
    results = data.get('results', {})
    pairs = []
    
    for qid, question_data in results.items():
        samplings = question_data.get('samplings', {})
        true_answer = question_data.get('true_final_result', '')
        
        # æ‰¾åˆ°æ­£æ ·æœ¬å’Œè´Ÿæ ·æœ¬
        positive_sample = None
        negative_sample = None
        
        for sid, sample in samplings.items():
            extracted_answer = sample.get('extracted_answer', '')
            is_correct = sample.get('is_correct', False)
            
            # æ£€æŸ¥æ˜¯å¦æœ‰token_details
            if 'token_details' not in sample or not sample['token_details']:
                continue
            
            if is_correct and positive_sample is None:
                positive_sample = (sid, sample)
            elif not is_correct and negative_sample is None:
                negative_sample = (sid, sample)
        
        # å¦‚æœæ‰¾åˆ°äº†é…å¯¹çš„æ­£è´Ÿæ ·æœ¬
        if positive_sample and negative_sample:
            pairs.append({
                'qid': qid,
                'true_answer': true_answer,
                'positive': {
                    'sid': positive_sample[0],
                    'sample': positive_sample[1]
                },
                'negative': {
                    'sid': negative_sample[0],
                    'sample': negative_sample[1]
                }
            })
    
    print(f"âœ… Found {len(pairs)} positive-negative pairs")
    return pairs

def analyze_sample_cluster_cohesion(sample, sample_type):
    """åˆ†æå•ä¸ªæ ·æœ¬çš„æ•´ä½“èšç±»å†…èšåº¦ (sample-wise)"""
    
    token_details = sample.get('token_details', [])
    if not token_details:
        return {
            'cluster_cohesion': 0.0,
            'optimal_clusters': 1,
            'min_inertia': 0.0,
            'best_silhouette_score': 0.0,
            'n_tokens': 0,
            'sample_type': sample_type
        }
    
    # æå–æ‰€æœ‰tokensçš„å‘é‡
    sample_vectors = []
    for token in token_details:
        if 'hidden_vector' in token:
            sample_vectors.append(token['hidden_vector'])
    
    if len(sample_vectors) < 2:
        return {
            'cluster_cohesion': 0.0,
            'optimal_clusters': 1,
            'min_inertia': 0.0,
            'best_silhouette_score': 0.0,
            'n_tokens': len(sample_vectors),
            'sample_type': sample_type
        }
    
    # è®¡ç®—æ•´ä¸ªæ ·æœ¬çš„èšç±»å†…èšåº¦
    cohesion_metrics = compute_cluster_cohesion(sample_vectors)
    cohesion_metrics['sample_type'] = sample_type
    
    return cohesion_metrics

def analyze_cluster_cohesion_for_pairs(pairs):
    """åˆ†ææ­£è´Ÿæ ·æœ¬å¯¹çš„èšç±»å†…èšåº¦ (sample-wise)"""
    
    analysis_results = {
        'pair_comparisons': [],
        'summary_statistics': {
            'total_pairs': len(pairs),
            'positive_stats': {
                'cluster_cohesion': [],
                'optimal_clusters': [],
                'best_silhouette_score': [],
                'n_tokens': []
            },
            'negative_stats': {
                'cluster_cohesion': [],
                'optimal_clusters': [],
                'best_silhouette_score': [],
                'n_tokens': []
            }
        }
    }
    
    for pair_idx, pair in enumerate(pairs):
        print(f"ğŸ”„ Processing pair {pair_idx + 1}/{len(pairs)}: {pair['qid']}")
        
        # åˆ†ææ­£æ ·æœ¬å’Œè´Ÿæ ·æœ¬
        positive_analysis = analyze_sample_cluster_cohesion(pair['positive']['sample'], 'positive')
        negative_analysis = analyze_sample_cluster_cohesion(pair['negative']['sample'], 'negative')
        
        pair_result = {
            'qid': pair['qid'],
            'true_answer': pair['true_answer'],
            'positive_analysis': positive_analysis,
            'negative_analysis': negative_analysis,
            'comparison': {
                'cohesion_difference': positive_analysis['cluster_cohesion'] - negative_analysis['cluster_cohesion'],
                'positive_cohesion': positive_analysis['cluster_cohesion'],
                'negative_cohesion': negative_analysis['cluster_cohesion'],
                'positive_tokens': positive_analysis['n_tokens'],
                'negative_tokens': negative_analysis['n_tokens']
            }
        }
        
        # æ·»åŠ åˆ°ç»Ÿè®¡æ•°æ®
        if positive_analysis['n_tokens'] >= 2:
            analysis_results['summary_statistics']['positive_stats']['cluster_cohesion'].append(positive_analysis['cluster_cohesion'])
            analysis_results['summary_statistics']['positive_stats']['optimal_clusters'].append(positive_analysis['optimal_clusters'])
            analysis_results['summary_statistics']['positive_stats']['best_silhouette_score'].append(positive_analysis['best_silhouette_score'])
            analysis_results['summary_statistics']['positive_stats']['n_tokens'].append(positive_analysis['n_tokens'])
        
        if negative_analysis['n_tokens'] >= 2:
            analysis_results['summary_statistics']['negative_stats']['cluster_cohesion'].append(negative_analysis['cluster_cohesion'])
            analysis_results['summary_statistics']['negative_stats']['optimal_clusters'].append(negative_analysis['optimal_clusters'])
            analysis_results['summary_statistics']['negative_stats']['best_silhouette_score'].append(negative_analysis['best_silhouette_score'])
            analysis_results['summary_statistics']['negative_stats']['n_tokens'].append(negative_analysis['n_tokens'])
        
        analysis_results['pair_comparisons'].append(pair_result)
    
    # è®¡ç®—æ€»ä½“ç»Ÿè®¡
    pos_cohesions = analysis_results['summary_statistics']['positive_stats']['cluster_cohesion']
    neg_cohesions = analysis_results['summary_statistics']['negative_stats']['cluster_cohesion']
    
    if pos_cohesions and neg_cohesions:
        analysis_results['overall_comparison'] = {
            'positive_mean': float(np.mean(pos_cohesions)),
            'positive_std': float(np.std(pos_cohesions)),
            'negative_mean': float(np.mean(neg_cohesions)),
            'negative_std': float(np.std(neg_cohesions)),
            'mean_difference': float(np.mean(pos_cohesions) - np.mean(neg_cohesions)),
            'effect_size': float((np.mean(pos_cohesions) - np.mean(neg_cohesions)) / 
                                np.sqrt((np.var(pos_cohesions) + np.var(neg_cohesions)) / 2))
        }
    
    return analysis_results

# ============================================================================
# VISUALIZATION FUNCTIONS
# ============================================================================

def create_visualizations(analysis_results):
    """åˆ›å»ºå¯è§†åŒ–å›¾è¡¨"""
    
    print("ğŸ“Š Creating visualizations...")
    
    # 1. æ€»ä½“å¯¹æ¯”ç®±å‹å›¾
    create_overall_comparison_plot(analysis_results)
    
    # 2. é€å¯¹æ¯”è¾ƒå›¾
    create_pairwise_comparison_plot(analysis_results)
    
    # 3. åˆ†å¸ƒå¯¹æ¯”å›¾
    create_distribution_comparison_plot(analysis_results)
    
    # 4. æ ·æœ¬çº§åˆ«åˆ†æå›¾
    create_sample_level_analysis_plot(analysis_results)

def create_overall_comparison_plot(analysis_results):
    """åˆ›å»ºæ€»ä½“å¯¹æ¯”ç®±å‹å›¾"""
    
    pos_cohesions = analysis_results['summary_statistics']['positive_stats']['cluster_cohesion']
    neg_cohesions = analysis_results['summary_statistics']['negative_stats']['cluster_cohesion']
    
    if not pos_cohesions or not neg_cohesions:
        return
    
    plt.figure(figsize=(10, 6))
    
    data_to_plot = [pos_cohesions, neg_cohesions]
    labels = ['Positive Samples\n(Correct Answers)', 'Negative Samples\n(Incorrect Answers)']
    colors = ['lightgreen', 'lightcoral']
    
    bp = plt.boxplot(data_to_plot, labels=labels, patch_artist=True)
    
    for patch, color in zip(bp['boxes'], colors):
        patch.set_facecolor(color)
        patch.set_alpha(0.7)
    
    plt.title('Sample-wise Cluster Cohesion: Positive vs Negative Samples', fontsize=14, fontweight='bold')
    plt.ylabel('Cluster Cohesion Score', fontsize=12)
    plt.grid(True, alpha=0.3)
    
    # æ·»åŠ ç»Ÿè®¡ä¿¡æ¯
    if 'overall_comparison' in analysis_results:
        stats = analysis_results['overall_comparison']
        plt.figtext(0.02, 0.02, 
                   f"Positive: Î¼={stats['positive_mean']:.3f}Â±{stats['positive_std']:.3f}\n"
                   f"Negative: Î¼={stats['negative_mean']:.3f}Â±{stats['negative_std']:.3f}\n"
                   f"Difference: {stats['mean_difference']:.3f}\n"
                   f"Effect Size: {stats['effect_size']:.3f}",
                   fontsize=10, verticalalignment='bottom')
    
    plt.tight_layout()
    plt.savefig(f"{VISUALIZATION_DIR}/overall_cluster_cohesion_comparison.png", 
                dpi=300, bbox_inches='tight')
    plt.show()  # æ˜¾ç¤ºå›¾è¡¨
    plt.close()
    
    print(f"âœ… Overall comparison plot saved to: {os.path.abspath(VISUALIZATION_DIR)}/overall_cluster_cohesion_comparison.png")

def create_pairwise_comparison_plot(analysis_results):
    """åˆ›å»ºé€å¯¹æ¯”è¾ƒå›¾ (sample-wise)"""
    
    pairs = analysis_results['pair_comparisons']
    if not pairs:
        return
    
    # æå–æ¯å¯¹æ ·æœ¬çš„èšç±»å†…èšåº¦
    positive_cohesions = []
    negative_cohesions = []
    qids = []
    
    for pair in pairs:
        pos_analysis = pair['positive_analysis']
        neg_analysis = pair['negative_analysis']
        
        if pos_analysis['n_tokens'] >= 2 and neg_analysis['n_tokens'] >= 2:
            positive_cohesions.append(pos_analysis['cluster_cohesion'])
            negative_cohesions.append(neg_analysis['cluster_cohesion'])
            qids.append(pair['qid'])
    
    if not positive_cohesions:
        return
    
    plt.figure(figsize=(12, 8))
    
    x = np.arange(len(qids))
    width = 0.35
    
    bars1 = plt.bar(x - width/2, positive_cohesions, width, label='Positive (Correct)', 
                    color='lightgreen', alpha=0.8)
    bars2 = plt.bar(x + width/2, negative_cohesions, width, label='Negative (Incorrect)', 
                    color='lightcoral', alpha=0.8)
    
    plt.xlabel('Question ID')
    plt.ylabel('Sample Cluster Cohesion')
    plt.title('Sample-wise Cluster Cohesion Comparison')
    plt.xticks(x, [f"Q{i+1}" for i in range(len(qids))], rotation=45)
    plt.legend()
    plt.grid(True, alpha=0.3)
    
    # æ·»åŠ æ•°å€¼æ ‡ç­¾
    for bar in bars1:
        height = bar.get_height()
        plt.text(bar.get_x() + bar.get_width()/2., height + 0.001,
                f'{height:.3f}', ha='center', va='bottom', fontsize=8)
    
    for bar in bars2:
        height = bar.get_height()
        plt.text(bar.get_x() + bar.get_width()/2., height + 0.001,
                f'{height:.3f}', ha='center', va='bottom', fontsize=8)
    
    plt.tight_layout()
    plt.savefig(f"{VISUALIZATION_DIR}/pairwise_cluster_cohesion_comparison.png", 
                dpi=300, bbox_inches='tight')
    plt.show()  # æ˜¾ç¤ºå›¾è¡¨
    plt.close()
    
    print(f"âœ… Pairwise comparison plot saved to: {os.path.abspath(VISUALIZATION_DIR)}/pairwise_cluster_cohesion_comparison.png")

def create_distribution_comparison_plot(analysis_results):
    """åˆ›å»ºåˆ†å¸ƒå¯¹æ¯”å›¾"""
    
    pos_cohesions = analysis_results['summary_statistics']['positive_stats']['cluster_cohesion']
    neg_cohesions = analysis_results['summary_statistics']['negative_stats']['cluster_cohesion']
    
    if not pos_cohesions or not neg_cohesions:
        return
    
    plt.figure(figsize=(12, 6))
    
    # å­å›¾1: ç›´æ–¹å›¾
    plt.subplot(1, 2, 1)
    plt.hist(pos_cohesions, bins=20, alpha=0.7, label='Positive', color='lightgreen', density=True)
    plt.hist(neg_cohesions, bins=20, alpha=0.7, label='Negative', color='lightcoral', density=True)
    plt.xlabel('Cluster Cohesion Score')
    plt.ylabel('Density')
    plt.title('Distribution Comparison')
    plt.legend()
    plt.grid(True, alpha=0.3)
    
    # å­å›¾2: ç´¯ç§¯åˆ†å¸ƒ
    plt.subplot(1, 2, 2)
    
    pos_sorted = np.sort(pos_cohesions)
    neg_sorted = np.sort(neg_cohesions)
    
    pos_y = np.arange(1, len(pos_sorted) + 1) / len(pos_sorted)
    neg_y = np.arange(1, len(neg_sorted) + 1) / len(neg_sorted)
    
    plt.plot(pos_sorted, pos_y, label='Positive', color='green', linewidth=2)
    plt.plot(neg_sorted, neg_y, label='Negative', color='red', linewidth=2)
    
    plt.xlabel('Cluster Cohesion Score')
    plt.ylabel('Cumulative Probability')
    plt.title('Cumulative Distribution Function')
    plt.legend()
    plt.grid(True, alpha=0.3)
    
    plt.tight_layout()
    plt.savefig(f"{VISUALIZATION_DIR}/distribution_comparison.png", 
                dpi=300, bbox_inches='tight')
    plt.show()  # æ˜¾ç¤ºå›¾è¡¨
    plt.close()
    
    print(f"âœ… Distribution comparison plot saved to: {os.path.abspath(VISUALIZATION_DIR)}/distribution_comparison.png")

def create_sample_level_analysis_plot(analysis_results):
    """åˆ›å»ºæ ·æœ¬çº§åˆ«è¯¦ç»†åˆ†æå›¾ (sample-wise)"""
    
    pairs = analysis_results['pair_comparisons']
    if not pairs or len(pairs) < 3:
        return
    
    # é€‰æ‹©å‰å‡ ä¸ªå¯¹è¿›è¡Œè¯¦ç»†åˆ†æ
    selected_pairs = pairs[:min(3, len(pairs))]
    
    fig, axes = plt.subplots(len(selected_pairs), 1, figsize=(12, 4 * len(selected_pairs)))
    if len(selected_pairs) == 1:
        axes = [axes]
    
    for idx, pair in enumerate(selected_pairs):
        ax = axes[idx]
        
        pos_analysis = pair['positive_analysis']
        neg_analysis = pair['negative_analysis']
        
        # æ˜¾ç¤ºæ ·æœ¬çº§åˆ«çš„èšç±»ä¿¡æ¯
        categories = ['Cluster\nCohesion', 'Optimal\nClusters', 'Best Silhouette\nScore']
        
        pos_values = [
            pos_analysis['cluster_cohesion'],
            pos_analysis['optimal_clusters'] / 10.0,  # æ ‡å‡†åŒ–æ˜¾ç¤º
            pos_analysis['best_silhouette_score']
        ]
        
        neg_values = [
            neg_analysis['cluster_cohesion'],
            neg_analysis['optimal_clusters'] / 10.0,  # æ ‡å‡†åŒ–æ˜¾ç¤º
            neg_analysis['best_silhouette_score']
        ]
        
        x = np.arange(len(categories))
        width = 0.35
        
        bars1 = ax.bar(x - width/2, pos_values, width, label='Positive', color='green', alpha=0.7)
        bars2 = ax.bar(x + width/2, neg_values, width, label='Negative', color='red', alpha=0.7)
        
        ax.set_xlabel('Metrics')
        ax.set_ylabel('Normalized Values')
        ax.set_title(f'Sample Analysis: {pair["qid"]} (Answer: {pair["true_answer"]})\n'
                    f'Tokens: Pos={pos_analysis["n_tokens"]}, Neg={neg_analysis["n_tokens"]}')
        ax.set_xticks(x)
        ax.set_xticklabels(categories)
        ax.legend()
        ax.grid(True, alpha=0.3)
        
        # æ·»åŠ æ•°å€¼æ ‡ç­¾
        for i, (bar1, bar2) in enumerate(zip(bars1, bars2)):
            height1 = bar1.get_height()
            height2 = bar2.get_height()
            
            if i == 1:  # optimal_clustersï¼Œæ˜¾ç¤ºåŸå§‹å€¼
                ax.text(bar1.get_x() + bar1.get_width()/2., height1 + 0.01,
                       f'{int(pos_analysis["optimal_clusters"])}', ha='center', va='bottom', fontsize=8)
                ax.text(bar2.get_x() + bar2.get_width()/2., height2 + 0.01,
                       f'{int(neg_analysis["optimal_clusters"])}', ha='center', va='bottom', fontsize=8)
            else:
                ax.text(bar1.get_x() + bar1.get_width()/2., height1 + 0.01,
                       f'{height1:.3f}', ha='center', va='bottom', fontsize=8)
                ax.text(bar2.get_x() + bar2.get_width()/2., height2 + 0.01,
                       f'{height2:.3f}', ha='center', va='bottom', fontsize=8)
    
    plt.tight_layout()
    plt.savefig(f"{VISUALIZATION_DIR}/sample_level_analysis.png", 
                dpi=300, bbox_inches='tight')
    plt.show()  # æ˜¾ç¤ºå›¾è¡¨
    plt.close()
    
    print(f"âœ… Sample-level analysis plot saved to: {os.path.abspath(VISUALIZATION_DIR)}/sample_level_analysis.png")

# ============================================================================
# MAIN EXECUTION
# ============================================================================

def main():
    print("="*60)
    print("CAUSAL JUDGMENT CLUSTER COHESION ANALYSIS (SAMPLE-WISE)")
    print("="*60)
    
    # 1. åŠ è½½æ•°æ®
    data = load_causal_judgment_data(INPUT_PATH)
    if not data:
        print("âŒ Failed to load data. Exiting.")
        return
    
    # 2. æå–æ­£è´Ÿæ ·æœ¬å¯¹
    pairs = extract_positive_negative_pairs(data)
    if not pairs:
        print("âŒ No valid positive-negative pairs found. Exiting.")
        return
    
    # 3. åˆ†æèšç±»å†…èšåº¦
    print("\nğŸ”„ Analyzing sample-wise cluster cohesion...")
    analysis_results = analyze_cluster_cohesion_for_pairs(pairs)
    
    # 4. ä¿å­˜ç»“æœ
    output_file = f"{OUTPUT_DIR}/cluster_cohesion_analysis.json"
    with open(output_file, 'w', encoding='utf-8') as f:
        json.dump(analysis_results, f, indent=2, ensure_ascii=False)
    
    print(f"âœ… Analysis results saved to: {os.path.abspath(output_file)}")
    
    # 5. åˆ›å»ºå¯è§†åŒ–
    create_visualizations(analysis_results)
    
    # 6. æ‰“å°æ€»ç»“
    print("\n" + "="*60)
    print("ANALYSIS SUMMARY")
    print("="*60)
    
    if 'overall_comparison' in analysis_results:
        stats = analysis_results['overall_comparison']
        print(f"ğŸ“Š Total pairs analyzed: {len(pairs)}")
        print(f"ğŸ“ˆ Positive samples mean cohesion: {stats['positive_mean']:.4f} Â± {stats['positive_std']:.4f}")
        print(f"ğŸ“‰ Negative samples mean cohesion: {stats['negative_mean']:.4f} Â± {stats['negative_std']:.4f}")
        print(f"ğŸ” Mean difference: {stats['mean_difference']:.4f}")
        print(f"ğŸ“ Effect size (Cohen's d): {stats['effect_size']:.4f}")
        
        # è§£é‡Šæ•ˆåº”é‡
        effect_size = abs(stats['effect_size'])
        if effect_size < 0.2:
            effect_desc = "negligible"
        elif effect_size < 0.5:
            effect_desc = "small"
        elif effect_size < 0.8:
            effect_desc = "medium"
        else:
            effect_desc = "large"
        
        print(f"ğŸ“‹ Effect size interpretation: {effect_desc}")
        
        direction = "higher" if stats['mean_difference'] > 0 else "lower"
        print(f"ğŸ¯ Conclusion: Positive samples show {direction} cluster cohesion than negative samples")
    
    print(f"\nğŸ“ Output files:")
    print(f"  - Analysis data: {os.path.abspath(output_file)}")
    print(f"  - Visualizations: {os.path.abspath(VISUALIZATION_DIR)}/")
    
    print("\nâœ… Analysis complete!")

if __name__ == "__main__":
    main()
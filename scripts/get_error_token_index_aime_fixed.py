# -*- coding: utf-8 -*-
"""
Complete JSONL processor with all required functions
Fixed for actual AIME data structure
"""

import json
import os
import gc
import requests
import re
import time
from pathlib import Path
from typing import Iterator, Dict, Any

# # âœ… APIé…ç½®
API_KEY = "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"
MODEL = "gpt-4.1"

# âœ… æ„å»ºé”™è¯¯åˆ†ææç¤ºè¯
def build_error_prompt(question, true_whole_answer, sample_whole_answer):
    """æ„å»ºç”¨äºé”™è¯¯åˆ†æçš„æç¤ºè¯"""
    return f"""
Here is a math question, its correct answer, and a sample answer that may contain mistakes.

ã€questionã€‘:
{question}

ã€Correct Answerã€‘:
{true_whole_answer}

ã€Incorrect Answerã€‘:
{sample_whole_answer}

Please help me:
1. Identify the earliest mistake in the incorrect answer and provide the complete sentence from that point.
2. Briefly explain why it is incorrect.
3. Find the fix sentence in correct answer that and fix the error.
4. Briefly explain why it can fix the error.

Please output in the following JSON format:
{{
  "first_error_sentence": "<sentence>",
  "error_reason": "<brief explanation>",
  "fix_sentence": "<sentence>",
  "fix_reason": "<brief explanation>"
}}
"""

# âœ… è°ƒç”¨GPT API
def call_custom_gpt_api(prompt):
    """è°ƒç”¨OpenAI API"""
    headers = {
        "Authorization": f"Bearer {API_KEY}",
        "Content-Type": "application/json"
    }
    payload = {
        "model": MODEL,
        "messages": [
            {"role": "system", "content": "You are a meticulous and precise comparer."},
            {"role": "user", "content": prompt}
        ]
    }

    try:
        response = requests.post(
            "https://api.openai.com/v1/chat/completions",
            headers=headers,
            json=payload,
            timeout=30  # æ·»åŠ è¶…æ—¶
        )

        if response.status_code != 200:
            raise Exception(f"API request failed: {response.status_code}, {response.text}")

        return response.json()["choices"][0]["message"]["content"]

    except requests.exceptions.Timeout:
        raise Exception("API request timeout")
    except requests.exceptions.RequestException as e:
        raise Exception(f"API request error: {str(e)}")

# âœ… æŸ¥æ‰¾å¥å­åœ¨tokenåºåˆ—ä¸­çš„ä½ç½®
def find_sentence_span_indices_robust(fragment, token_probs):
    """
    è¿”å› fragment åœ¨ token_probs ä¸­åŒ¹é…åˆ°çš„ token èŒƒå›´: (begin_index, end_index)
    ä½¿ç”¨å»é™¤ç©ºç™½å­—ç¬¦çš„æ–¹å¼åŒ¹é…
    """
    if not fragment or not token_probs:
        return -1, -1

    fragment_clean = re.sub(r"\s+", "", fragment)
    tokens = [entry["token"] for entry in token_probs]
    decoded_text = "".join(tokens)
    decoded_text_clean = re.sub(r"\s+", "", decoded_text)

    char_start_idx = decoded_text_clean.find(fragment_clean)
    if char_start_idx == -1:
        return -1, -1

    cumulative_len = 0
    begin_index = -1

    for idx, entry in enumerate(token_probs):
        token_clean = re.sub(r"\s+", "", entry["token"])
        prev_len = cumulative_len
        cumulative_len += len(token_clean)

        if begin_index == -1 and cumulative_len > char_start_idx:
            begin_index = idx
        if cumulative_len >= char_start_idx + len(fragment_clean):
            end_index = idx
            return begin_index, end_index

    return begin_index, len(token_probs) - 1  # fallback

# âœ… ç®€åŒ–çš„ç­”æ¡ˆåˆ¤æ–­å‡½æ•°ï¼ˆé€‚é…AIMEæ•°æ®é›†ï¼‰
def is_correct_answer(final_result, true_final_result):
    """
    åˆ¤æ–­final_resultæ˜¯å¦ä¸true_final_resultåŒ¹é…
    é€‚é…AIMEæ•°æ®é›†ï¼Œç›´æ¥è¿›è¡Œå­—ç¬¦ä¸²æ¯”è¾ƒ
    """
    return str(final_result).strip() == str(true_final_result).strip()

class JSONLProcessor:
    """
    é«˜æ•ˆçš„JSONLå¤„ç†å™¨ï¼Œæ”¯æŒå†…å­˜ç®¡ç†å’Œè¿›åº¦è·Ÿè¸ª
    é€‚é…AIMEæ•°æ®é›†çš„å®é™…ç»“æ„
    """

    def __init__(self, api_key: str, model: str = "gpt-4.1"):
        self.api_key = api_key
        self.model = model
        self.processed_count = 0
        self.error_count = 0
        self.start_time = None

    def convert_json_to_jsonl(self, input_path: str, output_path: str,
                             chunk_size: int = 1000):
        """
        å°†å¤§JSONæ–‡ä»¶è½¬æ¢ä¸ºJSONLï¼Œæ”¯æŒåˆ†å—å¤„ç†
        """
        print(f"ğŸ”„ Converting {input_path} to JSONL format...")

        # åˆ›å»ºè¾“å‡ºç›®å½•
        os.makedirs(os.path.dirname(output_path), exist_ok=True)

        # æ£€æŸ¥æ–‡ä»¶å¤§å°
        file_size = os.path.getsize(input_path)
        print(f"ğŸ“Š Input file size: {file_size / (1024**3):.2f} GB")

        with open(input_path, 'r', encoding='utf-8') as infile:
            data = json.load(infile)

        total_items = len(data)
        print(f"ğŸ“Š Total items to convert: {total_items}")

        with open(output_path, 'w', encoding='utf-8') as outfile:
            for i, (qid, sample) in enumerate(data.items()):
                line_data = {
                    "qid": qid,
                    "data": sample
                }
                outfile.write(json.dumps(line_data, ensure_ascii=False) + '\n')

                if (i + 1) % chunk_size == 0:
                    print(f"ğŸ“ˆ Converted {i + 1}/{total_items} items...")
                    # å¼ºåˆ¶åˆ·æ–°åˆ°ç£ç›˜
                    outfile.flush()

        print(f"âœ… Conversion complete! Saved to {output_path}")

        # æ¸…ç†å†…å­˜
        del data
        gc.collect()

    def process_jsonl_file(self, jsonl_path: str, output_path: str,
                          batch_size: int = 10, save_interval: int = 20):
        """
        æµå¼å¤„ç†JSONLæ–‡ä»¶ï¼Œæ”¯æŒæ‰¹å¤„ç†å’Œå®šæœŸä¿å­˜
        """
        self.start_time = time.time()
        results = {}

        # å¦‚æœè¾“å‡ºæ–‡ä»¶å·²å­˜åœ¨ï¼ŒåŠ è½½å·²å¤„ç†çš„ç»“æœ
        if os.path.exists(output_path):
            print("ğŸ“‚ Loading existing results...")
            try:
                with open(output_path, 'r', encoding='utf-8') as f:
                    results = json.load(f)
                    self.processed_count = len(results)
                    print(f"ğŸ“Š Loaded {self.processed_count} existing results")
            except (json.JSONDecodeError, FileNotFoundError):
                print("âš ï¸ Could not load existing results, starting fresh")
                results = {}

        # åˆ›å»ºè¾“å‡ºç›®å½•
        os.makedirs(os.path.dirname(output_path), exist_ok=True)

        with open(jsonl_path, 'r', encoding='utf-8') as f:
            batch = []
            line_count = 0

            for line in f:
                try:
                    line_data = json.loads(line.strip())
                    qid = line_data["qid"]

                    # è·³è¿‡å·²å¤„ç†çš„é¡¹ç›®
                    if qid in results:
                        print(f"â­ï¸ Skipping already processed: {qid}")
                        continue

                    batch.append((qid, line_data["data"]))
                    line_count += 1

                    # å¤„ç†æ‰¹æ¬¡
                    if len(batch) >= batch_size:
                        self._process_batch(batch, results)
                        batch = []

                        # å®šæœŸä¿å­˜å’Œæ¸…ç†å†…å­˜
                        if line_count % save_interval == 0:
                            self._save_results(results, output_path)
                            gc.collect()
                            self._print_progress()

                except json.JSONDecodeError as e:
                    print(f"âš ï¸ JSON decode error in line: {e}")
                    continue
                except Exception as e:
                    print(f"âš ï¸ Unexpected error processing line: {e}")
                    continue

            # å¤„ç†å‰©ä½™çš„é¡¹ç›®
            if batch:
                self._process_batch(batch, results)

        # æœ€ç»ˆä¿å­˜
        self._save_results(results, output_path)
        self._print_final_stats()

        return results

    def _process_batch(self, batch: list, results: dict):
        """å¤„ç†ä¸€ä¸ªæ‰¹æ¬¡çš„æ•°æ®"""
        for qid, sample in batch:
            try:
                print(f"ğŸ” Processing {qid}...")
                result = self._process_single_sample(qid, sample)
                if result:
                    results[qid] = result
                    self.processed_count += 1
                    print(f"âœ… Successfully processed {qid}")
                else:
                    print(f"âš ï¸ No valid result for {qid}")

            except Exception as e:
                print(f"âš ï¸ Error processing {qid}: {str(e)}")
                self.error_count += 1
                continue

    def _process_single_sample(self, qid: str, sample: dict) -> dict:
        """å¤„ç†å•ä¸ªæ ·æœ¬ - é€‚é…å®é™…AIMEæ•°æ®ç»“æ„"""
        try:
            # è·å–åŸºæœ¬ä¿¡æ¯ - é€‚é…å®é™…æ•°æ®ç»“æ„
            question = sample.get("full_question", "")
            true_final_result = sample.get("true_final_result", "")

            if not question or not true_final_result:
                print(f"âš ï¸ Missing full_question or true_final_result for {qid}")
                return None

            print(f"  ğŸ“‹ Question: {question[:100]}...")
            print(f"  âœ… True answer: {true_final_result}")

            # æ‰¾åˆ°æ­£æ ·æœ¬
            correct_sampling_id = None
            correct_sample_answer = None

            for sampling_id in ["sampling0", "sampling1", "sampling2"]:
                if sampling_id not in sample:
                    continue
                    
                sampling_data = sample[sampling_id]
                final_result = sampling_data.get("final_result", "")
                
                # ä½¿ç”¨ç®€åŒ–çš„åˆ¤æ–­é€»è¾‘
                if is_correct_answer(final_result, true_final_result):
                    correct_sampling_id = sampling_id
                    correct_sample_answer = sampling_data.get("whole_answer", "")
                    print(f"  âœ… Found correct sample: {sampling_id} (result: {final_result})")
                    break

            if correct_sample_answer is None:
                print(f"âš ï¸ No correct sampling found for {qid}")
                # æ‰“å°è°ƒè¯•ä¿¡æ¯
                for sampling_id in ["sampling0", "sampling1", "sampling2"]:
                    if sampling_id in sample:
                        final_result = sample[sampling_id].get("final_result", "")
                        print(f"    {sampling_id}: {final_result} (expected: {true_final_result})")
                return None

            sample_results = {}

            # å¤„ç†è´Ÿæ ·æœ¬
            for sampling_id in ["sampling0", "sampling1", "sampling2"]:
                if sampling_id not in sample:
                    continue
                    
                sampling = sample[sampling_id]
                final_result = sampling.get("final_result", "")

                # è·³è¿‡æ­£æ ·æœ¬
                if is_correct_answer(final_result, true_final_result):
                    print(f"  â­ï¸ Skipping correct sample: {sampling_id}")
                    continue

                incorrect_sample_answer = sampling.get("whole_answer", "")
                if not incorrect_sample_answer:
                    continue

                try:
                    print(f"  ğŸ” Analyzing incorrect sample: {sampling_id} (result: {final_result})")

                    # è°ƒç”¨API
                    prompt = build_error_prompt(question, correct_sample_answer, incorrect_sample_answer)
                    output = call_custom_gpt_api(prompt)

                    # è§£æç»“æœ
                    output = output.strip().strip("```")
                    if output.startswith("json"):
                        output = output[4:].strip()

                    output_json = json.loads(output)

                    # æŸ¥æ‰¾tokenç´¢å¼•
                    error_sentence = output_json.get("first_error_sentence", "")
                    fix_sentence = output_json.get("fix_sentence", "")

                    error_token_probs = sampling.get("token_probs", [])
                    correct_token_probs = sample[correct_sampling_id].get("token_probs", [])

                    error_begin_idx, error_end_idx = find_sentence_span_indices_robust(
                        error_sentence, error_token_probs
                    )
                    fix_begin_idx, fix_end_idx = find_sentence_span_indices_robust(
                        fix_sentence, correct_token_probs
                    )

                    sample_results[sampling_id] = {
                        "first_error_sentence": error_sentence,
                        "error_reason": output_json.get("error_reason", ""),
                        "fix_sentence": fix_sentence,
                        "fix_reason": output_json.get("fix_reason", ""),
                        "correct_sampling_id": correct_sampling_id,
                        "error_token_begin_index": error_begin_idx,
                        "error_token_end_index": error_end_idx,
                        "fix_token_begin_index": fix_begin_idx,
                        "fix_token_end_index": fix_end_idx
                    }

                    print(f"  âœ… Successfully analyzed {sampling_id}")

                except json.JSONDecodeError as e:
                    print(f"  âš ï¸ JSON decode error for {sampling_id}: {e}")
                    continue
                except Exception as e:
                    print(f"  âš ï¸ Error analyzing {sampling_id}: {e}")
                    continue

            return sample_results if sample_results else None

        except Exception as e:
            print(f"âš ï¸ Error in _process_single_sample for {qid}: {e}")
            return None

    def _save_results(self, results: dict, output_path: str):
        """ä¿å­˜ç»“æœåˆ°æ–‡ä»¶"""
        try:
            with open(output_path, 'w', encoding='utf-8') as f:
                json.dump(results, f, ensure_ascii=False, indent=2)
            print(f"ğŸ’¾ Saved {len(results)} results to {output_path}")
        except Exception as e:
            print(f"âš ï¸ Error saving results: {e}")

    def _print_progress(self):
        """æ‰“å°è¿›åº¦ä¿¡æ¯"""
        elapsed = time.time() - self.start_time
        speed = self.processed_count / elapsed if elapsed > 0 else 0
        print(f"ğŸ“Š Progress: {self.processed_count} processed, {self.error_count} errors, "
              f"{speed:.2f} items/sec, {elapsed:.1f}s elapsed")

    def _print_final_stats(self):
        """æ‰“å°æœ€ç»ˆç»Ÿè®¡ä¿¡æ¯"""
        elapsed = time.time() - self.start_time
        print(f"\nğŸ‰ Processing complete!")
        print(f"ğŸ“Š Total processed: {self.processed_count}")
        print(f"âš ï¸ Total errors: {self.error_count}")
        print(f"â±ï¸ Total time: {elapsed:.1f}s")
        if elapsed > 0:
            print(f"ğŸš€ Average speed: {self.processed_count / elapsed:.2f} items/sec")

# âœ… ä¸»å‡½æ•°
def main():
    # è·¯å¾„é…ç½® - é€‚é…AIMEæ•°æ®é›†
    range_tag = "11-30"
    START_YEAR = 2022
    END_YEAR = 2023
    MIN_PROBLEM_NUM = 1
    MAX_PROBLEM_NUM = 5
    SAMPLE_SIZE = 10
    
    input_json = f"./logits/aime_experiment_{MIN_PROBLEM_NUM}-{MAX_PROBLEM_NUM}_{START_YEAR}-{END_YEAR}_sample{SAMPLE_SIZE}.json"
    output_jsonl = f"./logits/aime_experiment_{MIN_PROBLEM_NUM}-{MAX_PROBLEM_NUM}_{START_YEAR}-{END_YEAR}_sample{SAMPLE_SIZE}.jsonl"
    output_results = f"./error_fix_index/aime_experiment_{MIN_PROBLEM_NUM}-{MAX_PROBLEM_NUM}_{START_YEAR}-{END_YEAR}_sample{SAMPLE_SIZE}_index.json"

    # åˆ›å»ºå¤„ç†å™¨
    processor = JSONLProcessor(API_KEY, MODEL)

    # æ­¥éª¤1: è½¬æ¢ä¸ºJSONLï¼ˆå¦‚æœè¿˜æ²¡æœ‰è½¬æ¢ï¼‰
    if not os.path.exists(output_jsonl):
        processor.convert_json_to_jsonl(input_json, output_jsonl)
    else:
        print(f"ğŸ“‚ JSONL file already exists: {output_jsonl}")

    # æ­¥éª¤2: å¤„ç†JSONLæ–‡ä»¶
    print("\nğŸš€ Starting JSONL processing...")
    results = processor.process_jsonl_file(
        jsonl_path=output_jsonl,
        output_path=output_results,
        batch_size=1,      # è®¾ç½®ä¸º1ä»¥ä¾¿è°ƒè¯•
        save_interval=5    # æ¯5ä¸ªé¡¹ç›®ä¿å­˜ä¸€æ¬¡
    )

    print(f"\nâœ… All processing complete! Results saved to {output_results}")

if __name__ == "__main__":
    main() 